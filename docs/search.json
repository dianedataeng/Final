[
  {
    "objectID": "RQ3Ready.html#objectives",
    "href": "RQ3Ready.html#objectives",
    "title": "Research Question 3",
    "section": "Objectives",
    "text": "Objectives\nThis research question looks to see if there are any disparities in the amount of testing and procedures a patient gets done in the ER. This can help health care professionals become aware of any blocks or social determinants that may impact patients from getting wholistic care in the ER.\n\nDependent variable:\n\nTotal Count of Diagnostic tests and procedures (10 variables into 1)\n\nIndependent variables:\n\nInsurance Status\nPoverty Category: Poor/Negative, Near Poor, Low Income, Middle Income, High Income\nSex\n\n\n\n*Notes Data Source & Preprocessing\nAfter reducing the 15 original variables into just two—insurance status and total tests—the dataset offered limited predictive value. To enhance the analysis, I merged it with another MEPS file containing additional demographic information, allowing for a more comprehensive and nuanced examination. I merged the MEPS 2023 Full Year Consolidated Data File to include additional variables. Using the patient ID, I linked patient data and added sex and poverty information to the dataset."
  },
  {
    "objectID": "RQ3Ready.html#data-visualization",
    "href": "RQ3Ready.html#data-visualization",
    "title": "Research Question 3",
    "section": "Data Visualization",
    "text": "Data Visualization\nThe data has an imbalanced data of 644 patients with no insurance v 3597 with insurance. The side-by-side bar chart in Figure 7 shows a left skewed normal distribution, with most patients in both insured and not insured having around 2 tests.  The proportion of the number of tests in the population is similar. \nFigure 7: Bar Chart of Number of ER Tests by Insurance Status\n\n\n\n\n\n\nTable 1 shows poverty levels and insurance status. For those without insurance, the largest shares fall into the Middle Income (32.76%) and High Income (27.64%) groups. Interestingly, Near Poor and Low-Income patients are more often insured, while a notable portion of uninsured patients come from middle- and high-income groups.\nTable 1: Proportion  of Patients by Poverty Category and Insurance Status\n\n\n\n\n\n\n\n\n\n\n\nInsurance\nPoor/Negative\nNear Poor\nLow Income\nMiddle Income\nHigh Income\n\n\n\n\nNo\n22.36%\n5.28%\n11.96%\n32.76%\n27.64%\n\n\nYes\n23.16%\n7.67%\n16.15%\n25.38%\n27.63%"
  },
  {
    "objectID": "RQ3Ready.html#multiple-linear-regression",
    "href": "RQ3Ready.html#multiple-linear-regression",
    "title": "Research Question 3",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\nThe multiple linear regression results (Table 2) showed that the strongest predictor was high income, which was associated with an average increase of 0.24 tests. The next significant predictor was insurance status, with insured patients surprisingly receiving 0.17 fewer tests on average compared to uninsured patients. Other factors, including near-poor status, low income, middle income, and sex, were not significant.\n\nKey Insight: - High income associated with an average increase of 0.24 tests per patient.\n\n\nKey Insight: - Insured patients receiving 0.17 fewer tests on average\n\nTable 2. Logistic Regression Ranked Coefficients from Strongest to Weakest\n\n\n\nPredictor\nEstimate\nStd. Error\nt value\nPr(&gt;\n\n\n\n\n(Intercept)\n2.73161\n0.08486\n32.188\n&lt;0.001\n\n\nHigh Income***\n0.23923\n0.07195\n3.325\n0.0009\n\n\nInsurance (Yes vs No)*\n-0.17027\n0.07134\n-2.387\n0.0171\n\n\nNear Poor\n0.11644\n0.11075\n1.051\n0.2932\n\n\nLow Income\n0.02835\n0.08245\n0.344\n0.731\n\n\nMiddle Income\n0.00577\n0.07258\n0.079\n0.9366\n\n\nSex (Female vs Male)\n-0.02602\n0.05236\n-0.497\n0.6193"
  },
  {
    "objectID": "RQ3Ready.html#poisson-regression",
    "href": "RQ3Ready.html#poisson-regression",
    "title": "Research Question 3",
    "section": "Poisson Regression",
    "text": "Poisson Regression\nThe Poisson regression is designed to count model data, which specifically addresses counting the number of total tests. Poisson Regression produced results like the linear regression, though the p-values for high income and insurance status were slightly weaker. The performance metrics of the two models were also nearly the same. The results showed that the strongest predictor was high income, which was associated with an average increase of 0.09 tests. The next significant predictor was insurance status, with insured patients surprisingly receiving 0.07 fewer tests on average compared to uninsured patients. The remaining factors were not significant.\n\nKey Insight: - High income associated with an average increase of 0.09 tests per patient.\n\n\nKey Insight: - Insured patients receiving 0.07 fewer tests on average\n\nTable 3. Poisson Regression Ranked Coefficients from Strongest to Weakest\n\n\n\nPredictor\nEstimate\nStd. Error\nt value\nPr(&gt;\n\n\n\n\n(Intercept)\n1.00333\n0.03723\n26.953\n&lt;0.001\n\n\nHigh Income**\n0.08890\n0.03174\n2.801\n0.0051\n\n\nInsurance (Yes vs No)*\n-0.06277\n0.03093\n-2.029\n0.0425\n\n\nNear Poor\n0.04439\n0.04910\n0.904\n0.3659\n\n\nLow Income\n0.01094\n0.03702\n0.295\n0.7677\n\n\nMiddle Income\n0.00236\n0.03262\n0.072\n0.9424\n\n\nSex (Female vs Male)\n-0.00980\n0.02317\n-0.423\n0.6723"
  },
  {
    "objectID": "RQ3Ready.html#random-forest-regression",
    "href": "RQ3Ready.html#random-forest-regression",
    "title": "Research Question 3",
    "section": "Random Forest Regression",
    "text": "Random Forest Regression\nThe Random Forest regression results indicate that poverty category is the strongest predictor of total tests. Insurance status is the next most important predictor, followed by sex, which has the smallest impact on the model’s predictions. The percent increase in MSE “measures how much the model’s prediction error increases, if the variable is randomly permuted”. The increase in node purity “measures the total improvement in the model’s fit contributed by each variable”. In both these metrics, the poverty category was the strongest predictor, followed by insurance then sex.\nTable 4: Random Forest Regression Results\n\n\n\nPredictor\n% Increase in MSE\nIncrease in Node Purity\n\n\n\n\nPoverty Category\n18.84\n31.90\n\n\nInsurance\n8.26\n12.07\n\n\nSex\n4.31\n7.16"
  },
  {
    "objectID": "RQ3Ready.html#rq3-best-model---poisson-regression",
    "href": "RQ3Ready.html#rq3-best-model---poisson-regression",
    "title": "Research Question 3",
    "section": "RQ3: Best Model - Poisson Regression",
    "text": "RQ3: Best Model - Poisson Regression\nThe performance of all three models was similar. The RMSE was 1.37, meaning the predicted number of tests was off by about 1.37 on average, and the MAE was 1.12, showing an average absolute error of 1.12 tests.\nThe Random Forest model had a slightly higher R² of 0.011 compared to 0.008 for both the Poisson and Multiple Linear Regression models, but overall the low R² indicates the models explain very little of the variation in total tests.\nOne limitation is the low variance in the total tests (around 1.9), which means most observations are close to the mean. Low variance can increase bias and lower R². Variable selection could not be performed because I did not have many variables to choose from after reducing the predictors from 17 to 4 key variables, additional variables were later merged from another dataset. Poisson regression can handle low variance and skewed data very well, so Poisson regression is the most appropriate model for this analysis.\nTable 5: Performance Metrics Comparisons: Random Forest, Poisson Regression, & Multiple Linear Model\n\n\n\nModel\nRMSE\nMAE\nR²\n\n\n\n\nRandom Forest\n1.37\n1.12\n0.011\n\n\nPoisson Regression\n1.37\n1.12\n0.008\n\n\nMultiple Linear Regression\n1.37\n1.12\n0.008"
  },
  {
    "objectID": "RQ2Ready.html#objective",
    "href": "RQ2Ready.html#objective",
    "title": "Research Question 2",
    "section": "Objective",
    "text": "Objective\nThe research question is looking to explore the cost behind these ER expenditures. Moreso, it looks to see if large costs are associated with certain diagnostic tests, procedures, or medications provided during the emergency room visit.\nTotal cost is defined as the total, whole ER expenditures so costs to doctors, facilities, and even patients. This can help healthcare professionals allocate resources towards areas where there are high costs and make efforts in lowering costs without compromising quality of care.\n\nDependent variable:\n\nTotal Cost\n\nIndependent variables:\n\nDiagnostic tests and procedures: MRI/CT, surgery, X-ray, lab tests, EKG, ultrasound, mammogram, vaccination, prescriptions, related condition"
  },
  {
    "objectID": "RQ2Ready.html#data-visualization",
    "href": "RQ2Ready.html#data-visualization",
    "title": "Research Question 2",
    "section": "Data Visualization",
    "text": "Data Visualization\nThe boxplot shows the total cost of ER visits has a median of $578.20, a mean of $1,227.90, and a maximum of $195,314.50.”\nFigure 1: Box Plot of Total Cost Distribution of ER Visits\n\n\n\n\n\n\nThis shows a left-skewed distribution of the total cost distribution of ER visits. There were also 367 cases with 0 costs, while there were 3874 cases with more than 0 out of pocket costs.\nFigure 2: Left Skewed Distribution of Total Cost of ER Visits"
  },
  {
    "objectID": "RQ2Ready.html#random-forest-model---regression",
    "href": "RQ2Ready.html#random-forest-model---regression",
    "title": "Research Question 2",
    "section": "Random Forest Model - Regression",
    "text": "Random Forest Model - Regression\nThe random forest model was chosen because it is able to rank important variables and can handle skewed data and outliers. The random forest model handles outliers by creating hundreds of random subsets of data within these random trees. Some of these outliers can impact a few trees, but overall it will not have a big effect on the predictions.\nOn the training data, the Random Forest showed a low percentage of variance explained and high mean squared residuals, mainly because the extreme outliers had a large impact. The metrics from the test set are more important because they show how well the model predicts data it hasn’t seen before. The strongest predictors for high ER total costs were patients who were admitted in patient and those who had surgery. The other variables had slight or no effects on ER costs. Random Forest model does not tell you the degree of negative or positive effect on ER costs.\nFigure 3: Variable Importance Plot – Random Forest"
  },
  {
    "objectID": "RQ2Ready.html#multiple-linear-regression",
    "href": "RQ2Ready.html#multiple-linear-regression",
    "title": "Research Question 2",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\nI performed a multiple linear regression once again on predicting total cost on the above variables in the Random Forest Model. Although the multiple linear regression can predict continuous variables, it cannot handle outliers very well. The results showed that patients who were admitted in patient was the strongest predictor in lower ER costs, this shows that there is a $1,589 decrease for patients who were admitted in patient. This may possibly be because the total cost is now outside of the ER visit, rather an inpatient cost. The second strongest predictor were patients who get an MRI CT have a $936.09 increase in ER costs, patients with ultrasound increase ER costs by $648, and patients with lab test increase ER costs by $336.39. We should also note that the EKG was close to the 0.05 p value at 0.06 barely making the cutoff, with a positive estimate at $384.07.\n\nKey Insight: - Patients Admitted Inpatient show a $1,589 decrease in ER costs.\n\n\nKey Insight: - MRI/CT scans were associated with a $936.09 increase in ER costs.\n\n\nKey Insight: - Ultrasound and lab tests also contributed to higher costs, with increases of $648 and $336.39, respectively.\n\n\nKey Insight: - EKG was borderline significant (p = 0.065) with a positive estimate of $384.07, suggesting a modest cost increase associated with EKGs.\n\nThese results highlight that procedures and diagnostics significantly influence ER costs, while inpatient admission may shift costs away from the ER.\nTable 1  Multiple Linear Regression Ranked Coefficients from Strongest to Weakest\n\n\n\nPredictor\nEstimate\nStd. Error\nt value\np-value\n\n\n\n\nAdmitted***\n-1589.18\n201.76\n-7.877\n4.68e-15\n\n\nmri_ct***\n936.09\n188.78\n4.958\n7.51e-07\n\n\nUltrasound*\n648.08\n251.73\n2.574\n0.010088\n\n\nlab_tests*\n336.39\n169.31\n1.987\n0.047028\n\n\nEkg\n384.07\n208.61\n1.841\n0.065704\n\n\nsurgery\n495.41\n341.66\n1.450\n0.147165\n\n\nxray\n112.29\n166.11\n0.676\n0.499099\n\n\nvaccination\n-511.64\n639.53\n-0.800\n0.423760\n\n\nrx_given\n-64.81\n175.65\n-0.369\n0.712158\n\n\nrelated_condition\n90.41\n227.79\n0.397\n0.691458\n\n\nmammogram\n-437.42\n1901.22\n-0.230\n0.818052\n\n\n(Intercept)\n867.75\n227.04\n3.822\n0.000135"
  },
  {
    "objectID": "RQ2Ready.html#rq2-best-model-random-forest",
    "href": "RQ2Ready.html#rq2-best-model-random-forest",
    "title": "Research Question 2",
    "section": "RQ2: Best Model – Random Forest",
    "text": "RQ2: Best Model – Random Forest\nReferring to Table 4, the multiple linear regression model had an RMSE of $3,689.77, indicating that predicted ER costs differed from actual costs by roughly this amount on average. The MAE was $1,147.58, showing that predictions were about $1,147 away from the true ER cost. The R² value of 0.132 indicates that the model explains only 13.2% of the variation in ER costs, suggesting that linear regression is not well-suited for predicting ER costs in this dataset.\nIn comparison, the Random Forest model performed much better, with an RMSE of $997.89, an MAE of $243.08, and an R² of 0.97. This means that predictions were much closer to actual costs and that the model captured 97% of the variation in ER costs, making it a more reliable method for predicting total ER expenditures, especially given the presence of extreme outliers.\nWhile linear regression provides precise estimates of how each predictor increases or decreases total costs, the Random Forest model does not indicate the direction of the predictors. But the Random Forest is a better model than the linear regression because it is able to handle outliers through their random trees. Extreme outliers in ER costs disproportionately affected the regression line, inflating errors and lowering R².\n  Table 2: Performance Metrics Comparisons: Random Forest & Multiple Linear Model\n\n\n\nModel\nRMSE\nMAE\nR-Squared\n\n\n\n\nRandom Forest\n997.89\n243.08\n0.97\n\n\nMultiple Linear Model\n3689.77\n1147.58\n0.132"
  },
  {
    "objectID": "RQ1Ready.html#objective",
    "href": "RQ1Ready.html#objective",
    "title": "Research Question 1",
    "section": "Objective",
    "text": "Objective\nThis research question focuses on identifying the factors that determine whether an ER visit leads to an inpatient hospital admission. While many patients are treated and released on the same day, some require longer stays for observation or additional care.\n\nDependent variable:\n\nInpatient admission\n\nIndependent variables:\n\nDiagnostic tests and procedures: MRI/CT, surgery, X-ray, lab tests, EKG, ultrasound, mammogram, vaccination, prescriptions, related condition\nInsurance status\n\n\nUnderstanding these factors can help healthcare providers plan more effective treatment strategies. Hospital administrators can also benefit from this information by predicting which patients may require extended care, supporting improved planning and resource management."
  },
  {
    "objectID": "RQ1Ready.html#data-visualization",
    "href": "RQ1Ready.html#data-visualization",
    "title": "Research Question 1",
    "section": "Data Visualization",
    "text": "Data Visualization\nFigure 1 illustrates that a smaller proportion of patients were admitted as inpatients v not admitted (21% v 79%). This highlights the skewed and imbalanced population, but this imbalance will be considered in the analysis.\nFigure 1: Count of ER Visits by In Patient Admission Status"
  },
  {
    "objectID": "RQ1Ready.html#logistic-regression",
    "href": "RQ1Ready.html#logistic-regression",
    "title": "Research Question 1",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nThe logistic regression showed certain procedures—like MRI/CT scans, surgery, lab work, EKGs, ultrasounds, and having a related condition—were linked to higher odds of being admitted.\nOn the other hand, patients who had insurance or were given a prescription were less likely to be admitted (Figure 3). These two factors turned out to be the strongest predictors of lower inpatient admission.\nThose with insurance have 88% lower odds of being admitted and those given a prescription have 73% lower odds of being admitted. Those who have lab tests have 128% higher odds of admission, patients with related conditions have 162% higher odds of admission, patients with EKGs done have 87% higher odds of admission, patients with surgery have 145% higher odds of admission, patients with ultrasound have 72% higher odds of admission, and patients with MRI CT scans have 53% higher odds of admission.\n\nKey Insight: Patients with insurance have 88% lower odds of inpatient admission.\nKey Insight: Patients who have had lab tests have 128% lower odds of inpatient admission.\nKey Insight: Patients with surgery have 145% lower odds of inpatient admission.\n\nTable 1. Logistic Regression Ranked Coefficients from Strongest to Weakest\n\n\n\n\n\n\n\n\n\n\nPredictor\nEstimate\nStd. Error\nz-value\np-value\n\n\n\n\nInsurance***\n-2.13319\n0.11567\n18.442\n&lt; 2e-16\n\n\nrx_given***\n-1.30270\n0.13127\n9.924\n&lt; 2e-16\n\n\nlab_tests***\n0.82450\n0.10913\n7.555\n4.19e-14\n\n\nrelated_condition***\n0.96239\n0.17494\n5.501\n3.77e-08\n\n\nekg***\n0.62813\n0.11301\n5.558\n2.72e-08\n\n\nsurgery***\n0.89785\n0.18537\n4.844\n1.28e-06\n\n\nultrasound***\n0.54345\n0.13630\n3.987\n6.69e-05\n\n\nmri_ct***\n0.42790\n0.10906\n3.924\n8.72e-05\n\n\nXray\n-0.03592\n0.10341\n0.347\n0.728\n\n\nVaccination\n-0.18130\n0.48603\n0.373\n0.709\n\n\nMammogram\n-13.87172\n238.18570\n0.058\n0.954\n\n\n(Intercept)\n-1.09992\n0.19147\n5.744\n9.22e-09\n\n\n\nTable 2: Logistic Regression Confusion Matrix\n\n\n\nn=4241\n\n\n\n\n\n\nPrediction\nPredicted No\nPredicted Yes\n\n\nActual No\n647\n124\n\n\nActual Yes\n29\n48\n\n\n\nTable 2 shows the logistic regression confusion matrix, the true positive rate, the rate that correctly predicts those who will be admitted is 62.3% and true negative rate is 83.9%, the rate that correctly predicts who will not be admitted. The type 1 error, which falsely predicts patients being admitted when they are not actually admitted is 16.1% and the type 2 error which also falsely predicts patients not being admitted, when they are truly admitted is 37.7%. Overall, the model has ~82% accuracy rate\nTrue positive rate (62.3%), true negative rate (83.9%), type 1 error (16.1%), and type 2 error (37.7%)."
  },
  {
    "objectID": "RQ1Ready.html#random-forest-tree---classification",
    "href": "RQ1Ready.html#random-forest-tree---classification",
    "title": "Research Question 1",
    "section": "Random Forest Tree - Classification",
    "text": "Random Forest Tree - Classification\nThe Random Forest model identifies the key factors that influence whether a patient is admitted. This classification approach works by generating hundreds of decision trees and aggregating their results to determine which predictors contribute most to the outcome.\nThe model used 362 trees to achieve the lowest mean squared error. The results showed that insurance coverage, lab tests, prescriptions given, and EKG were the most influential variables for predicting patient admission. In contrast, vaccination and mammogram variables contributed very little, like the findings from the logistic regression analysis. Figure 3 presents a plot showing the relative importance of each predictor in the Random Forest model. Table 3 presents the corresponding confusion matrix, showing an overall accuracy of approximately 82%.\nFigure 3: Variable Importance Plot – Random Forest\n\n\n\n\n\n\n\n\n\n Table 3: Random Forest Confusion Matrix & Metrics\nAccuracy: 81.7%, Sensitivity: 96.6%, Specificity: 23.3%\n\n\n\nn=4241\nPredicted No\nPredicted Yes\n\n\n\n\nActual No\n653\n132\n\n\nActual Yes\n23\n40\n\n\n\nTrue positive rate (63.5%%), true negative rate (83.2%), type 1 error (16.8%), and type 2 error (36.5%)."
  },
  {
    "objectID": "RQ1Ready.html#rq1-best-model-random-forest",
    "href": "RQ1Ready.html#rq1-best-model-random-forest",
    "title": "Research Question 1",
    "section": "RQ1 Best Model – Random Forest",
    "text": "RQ1 Best Model – Random Forest\nThe logistic regression and Random Forest models produced similar results, achieving roughly 82% accuracy. The logistic regression model offers greater interpretability, showing that insurance status and whether a prescription was given have negative coefficients. This makes it easier to understand the direction of these effects and how these factors relate to the likelihood of an ER visit resulting in inpatient admission.\nThe Random Forest model, however, is unable to provide this level of detail. However it does handle imbalanced data better because it builds hundreds of decision trees, each using a different subset of the data. While the two models have similar rates of accuracy, sensitivity, specificity, etc., the Random Forest’s approach allows it to more effectively capture patterns in the skewed admission data, which makes it a better model."
  },
  {
    "objectID": "References.html",
    "href": "References.html",
    "title": "References",
    "section": "",
    "text": "GeeksforGeeks. (n.d.). Regression using k-nearest neighbors in R programming.\nJameson, J. (n.d.). API 222 files – Section 2.\nMcGill, R., Tukey, J. W., & Larsen, W. A. (1978). Variations of box plots. The American Statistician, 32(1), 12–16.\nMEPS. (n.d.-a). HC-248E: 2023 full year consolidated data file. Agency for Healthcare Research and Quality.\nMEPS. (n.d.-b). Survey background. Agency for Healthcare Research and Quality.\nMEPS. (n.d.-c). HC-251: 2023 full year consolidated data file. Agency for Healthcare Research and Quality.\nPlotly. (n.d.). R graphing library.\nDaily Dose of Data Science. (n.d.). Poisson regression vs linear regression."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Emergency Room Utilization: Admissions, Costs, and Testing Patterns",
    "section": "",
    "text": "Emergency room care is one of the most expensive components of U.S. healthcare, and costs have risen dramatically in recent years. Understanding the drivers of high ER expenditures and the factors that lead to hospital admission can help policymakers, hospital administrators, and insurers design more efficient care pathways and reduce financial burden on patients."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Emergency Room Utilization: Admissions, Costs, and Testing Patterns",
    "section": "",
    "text": "Emergency room care is one of the most expensive components of U.S. healthcare, and costs have risen dramatically in recent years. Understanding the drivers of high ER expenditures and the factors that lead to hospital admission can help policymakers, hospital administrators, and insurers design more efficient care pathways and reduce financial burden on patients."
  },
  {
    "objectID": "index.html#research-questions",
    "href": "index.html#research-questions",
    "title": "Emergency Room Utilization: Admissions, Costs, and Testing Patterns",
    "section": "Research Questions",
    "text": "Research Questions\n\nRQ1: What predictors can help determine whether an ER visit results in inpatient admission?\n\nRQ2: Which characteristics of an ER visit are most strongly associated with the highest total ER expenditure?\n\nRQ3: What impacts the number of tests and procedures a patient gets done in the ER?"
  },
  {
    "objectID": "index.html#data-source-description",
    "href": "index.html#data-source-description",
    "title": "Emergency Room Utilization: Admissions, Costs, and Testing Patterns",
    "section": "Data Source & Description",
    "text": "Data Source & Description\nThe dataset is under the 2023 Medical Expenditure Panel Survey, which surveys a geographically diverse population of the US and their medical providers. A sample of households are interviewed and surveyed for information, then their medical providers are contacted for more information. The medical providers include doctors, hospitals, pharmacies, etc. This dataset specifically covers 2023 and reports data on household reported emergency visits. Only households that have reported an emergency room visit were included in the dataset.\nThe original MEPS ER visit file includes 4,241 unique patients and 53 variables. According to MEPS, this file captures information about each emergency room visit, including: services and procedures performed, diagnostic testing, medications provided, total expenditures, and sources of payment."
  },
  {
    "objectID": "index.html#key-variable-dictionary",
    "href": "index.html#key-variable-dictionary",
    "title": "Emergency Room Utilization: Admissions, Costs, and Testing Patterns",
    "section": "Key Variable Dictionary",
    "text": "Key Variable Dictionary\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nperson_id\nUnique MEPS identifier (DUPERSID)\n\n\nadmitted\nWhether the ER visit resulted in inpatient admission\n\n\nmri_ct\nMRI or CT scan performed\n\n\nsurgery\nMinor surgical procedure performed\n\n\nxray\nX-ray received\n\n\nlab_tests\nLaboratory tests completed\n\n\nekg\nElectrocardiogram performed\n\n\nultrasound\nUltrasound completed\n\n\nmammogram\nMammogram received\n\n\nvaccination\nVaccination provided\n\n\nrx_given\nPrescription medication given\n\n\nrelated_condition\nVisit related to prior condition\n\n\ntotal_cost\nTotal ER expenditure (facility + physician)\n\n\noop_facility\nOut-of-pocket cost for ER facility\n\n\noop_doctor\nOut-of-pocket cost for ER doctor\n\n\nprivate_fac\nPrivate insurance payment (facility)\n\n\nprivate_doc\nPrivate insurance payment (doctor)\n\n\nmedicaid_fac\nMedicaid payment (facility)\n\n\nmedicaid_doc\nMedicaid payment (doctor)\n\n\nmedicare_fac\nMedicare payment (facility)\n\n\nmedicare_doc\nMedicare payment (doctor)\n\n\noop_total\nTotal out-of-pocket cost (facility + doctor)\n\n\ninsurance_type\nDerived insurance category\n\n\nsex\nMale / Female\n\n\npoverty_cat\nPoverty classification (5 levels)"
  },
  {
    "objectID": "index.html#data-preprocessing",
    "href": "index.html#data-preprocessing",
    "title": "Emergency Room Utilization: Admissions, Costs, and Testing Patterns",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nFrom the original 53 variables, 23 were selected as relevant for the research questions.\n\nDiagnostic tests and procedures (MRI/CT, surgery, X-ray, lab tests, EKG, ultrasound, mammogram, vaccination, prescriptions, related condition) used codes like: binary factors (0,1)\n\n-8 → Don’t know\n-7 → Refused\n95 → Not received\n\nAdmission outcome: - binary factor for modeling.\n\n0 = Not admitted\n\n1 = Admitted\n\nInsurance: New binary variable created:\n\nIf all insurance payments (Medicaid, Medicare, Private) were zero or missing → Uninsured (0)\n\nIf any insurance payment &gt; 0 → Insured (1)\n\nTotal tests: A composite variable (total_tests) counting the total number of diagnostic tests and procedures received during an ER visit, including MRI/CT, surgery, X-ray, lab tests, EKG, ultrasound, mammogram, vaccinations, and prescriptions.\n\nThe ER visit dataset was merged with the MEPS 2023 Full-Year Consolidated Data using the patient identifier to incorporate:\n- Sex\n- Poverty category (five levels: Poor/Negative, Near Poor, Low Income, Middle Income, High Income)"
  },
  {
    "objectID": "Future.html",
    "href": "Future.html",
    "title": "Conclusion and Future Work",
    "section": "",
    "text": "The Emergency Visit MEPS data provided important insights into inpatient admissions, total costs, and the number of tests performed. Key predictors included procedures, tests, insurance status, and total costs. Several models were used, including multiple linear regression, Poisson regression, random forest regression, random forest classification, and logistic regression.\nFor research questions 1 and 2, the random forest models performed best because they handled imbalanced data and extreme outliers well. However, the logistic regression model was valuable in showing the direction and size of each predictor’s effect.\nFor research question 3, the high variance in the data made Poisson regression the most appropriate model, which identified two statistically significant predictors.\nThese models can help healthcare providers with hospital planning, resource allocation, and policies for holistic, quality patient care."
  },
  {
    "objectID": "Future.html#conclusion",
    "href": "Future.html#conclusion",
    "title": "Conclusion and Future Work",
    "section": "",
    "text": "The Emergency Visit MEPS data provided important insights into inpatient admissions, total costs, and the number of tests performed. Key predictors included procedures, tests, insurance status, and total costs. Several models were used, including multiple linear regression, Poisson regression, random forest regression, random forest classification, and logistic regression.\nFor research questions 1 and 2, the random forest models performed best because they handled imbalanced data and extreme outliers well. However, the logistic regression model was valuable in showing the direction and size of each predictor’s effect.\nFor research question 3, the high variance in the data made Poisson regression the most appropriate model, which identified two statistically significant predictors.\nThese models can help healthcare providers with hospital planning, resource allocation, and policies for holistic, quality patient care."
  },
  {
    "objectID": "Future.html#future-work",
    "href": "Future.html#future-work",
    "title": "Conclusion and Future Work",
    "section": "Future Work",
    "text": "Future Work\nFuture work could involve linking additional MEPS data using the unique patient ID. This might include demographic details such as race, age, geographic location, and type of insurance, which could provide deeper insight into health disparities and patterns across different patient groups."
  },
  {
    "objectID": "Codes.html",
    "href": "Codes.html",
    "title": "RQ2",
    "section": "",
    "text": "Research Question 1: What predictors can help determine whether an ER visit results in inpatient admission?\nLibrary Download\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.5.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n\n\n✔ broom        1.0.10     ✔ recipes      1.3.1 \n✔ dials        1.4.2      ✔ rsample      1.3.1 \n✔ dplyr        1.1.4      ✔ tailor       0.1.0 \n✔ ggplot2      4.0.1      ✔ tidyr        1.3.1 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ purrr        1.1.0      ✔ yardstick    1.3.2 \n\n\nWarning: package 'dials' was built under R version 4.5.2\n\n\nWarning: package 'dplyr' was built under R version 4.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\nWarning: package 'infer' was built under R version 4.5.2\n\n\nWarning: package 'modeldata' was built under R version 4.5.2\n\n\nWarning: package 'parsnip' was built under R version 4.5.2\n\n\nWarning: package 'recipes' was built under R version 4.5.2\n\n\nWarning: package 'rsample' was built under R version 4.5.2\n\n\nWarning: package 'tailor' was built under R version 4.5.2\n\n\nWarning: package 'tune' was built under R version 4.5.2\n\n\nWarning: package 'workflows' was built under R version 4.5.2\n\n\nWarning: package 'workflowsets' was built under R version 4.5.2\n\n\nWarning: package 'yardstick' was built under R version 4.5.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.5.2\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-10\n\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.5.2\n\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.5.2\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.5.2\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.5.2\n\n\nrandomForest 4.7-1.2\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:ranger':\n\n    importance\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nlibrary(tree)\n\nWarning: package 'tree' was built under R version 4.5.2\n\nlibrary(ISLR)\n\nWarning: package 'ISLR' was built under R version 4.5.2\n\nlibrary(dplyr)\nlibrary (plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:xgboost':\n\n    slice\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary (car)\n\nWarning: package 'car' was built under R version 4.5.2\n\n\nLoading required package: carData\n\n\nWarning: package 'carData' was built under R version 4.5.2\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nResearch Questions: 2. Which type of ER visits are the costliest for total ER expenditures? Types of tests / diagnostics? *note: Total ER expenditure is different than out of pocket\n\nOGData= read.csv(\"C:/Users/diane/downloads/h248e.csv\")\n\nLooking for Missing Values -1,-7,-8 shows missing / dont know vairbales completely remove varibles with these negative values - this dropped 317 observations\nRenaming Variables\n\nOGData_clean &lt;- OGData %&gt;%\n  # ── Keep only the variables we actually use across all 3 RQs ──\ndplyr:: select(\n    # Person-level ID and survey weight\n    person_id   = DUPERSID,\n    weight      = PERWT23F,\n    \n    # ── RQ1: Predict hospital admission ──\n    admitted    = ERHEVIDX,        # will recode below\n    \n    # Tests & diagnostics performed in ER (all yes/no → 0/1)\n    mri_ct      = MRI_M18,\n    surgery     = SURGPROC,\n    xray        = XRAYS_M18,\n    lab_tests   = LABTEST_M18,\n    ekg         = EKG_M18,\n    ultrasound  = SONOGRAM_M18,\n    mammogram   = MAMMOG_M18,\n    vaccination = RCVVAC_M18,\n    rx_given    = MEDPRESC,\n    related_condition = VSTRELCN,\n    \n    # ── RQ2: Total ER cost drivers ──\n    total_cost  = ERXP23X,         # total expenditure (facility + doctor)\n    \n    # ── RQ3: Out-of-pocket by insurance ──\n    oop_facility = ERFSF23X,       # self/family OOP facility\n    oop_doctor   = ERDSF23X,       # self/family OOP doctor\n    \n    private_fac  = ERFPV23X,\n    private_doc  = ERDPV23X,\n    medicaid_fac = ERFMD23X,\n    medicaid_doc = ERDMD23X,\n    medicare_fac = ERFMR23X,\n    medicare_doc = ERDMR23X\n  )\n\nAdding in Insurance Information\n\n#Cleaning Data to find Insurance v No Insurance\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(Insurance = case_when(\n    (private_fac &gt; 0  |  private_doc &gt; 0 | medicaid_fac &gt; 0 | medicaid_doc &gt; 0 | medicare_fac &gt; 0 | medicare_doc &gt; 0) ~ \"1\",\n    TRUE ~ \"0\"\n  ))\n\nOGData_clean$Insurance &lt;- as.numeric(OGData_clean$Insurance)\n\nCleaning up binary data Clean More Data - Deal with 95 & 1&2 to 0,1 remove -8 dont know variables 1 is yes 2 is no - changing to 0,1 - no - 0 yes 1\n\nyesno_vars &lt;- c(\n  \"mri_ct\", \"surgery\", \"xray\", \"lab_tests\", \"ekg\",\n  \"ultrasound\", \"mammogram\", \"vaccination\", \"rx_given\",\n  \"related_condition\")\n\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(across(all_of(yesno_vars), ~ ifelse(. == 1, 1, 0))) #keeps all the 1's and replaces the rest with 0\n\n#cleaning admitted inpatient for RQ1\nOGData_clean$admitted &lt;- ifelse(OGData_clean$admitted == \"-1\", 0, 1) #-1 not admitted - changing to 0;; recoding 1 to be admitted\ntable(OGData_clean$admitted) #not admitted 3345; admitted:896\n\n\n   0    1 \n3345  896 \n\n\nData Visualization for RQ1 - Skewed Data\n\n#creating new dataset to recode Admitted ad MRI CT to Yes / no\nRQ1Viz &lt;- OGData_clean %&gt;%\nmutate(admitted = factor(admitted, levels = c(0,1), labels = c(\"No\",\"Yes\")),\n        mri_ct = factor(mri_ct, levels = c(0,1), labels = c(\"No\",\"Yes\")))\n\n\nggplotly (ggplot(RQ1Viz, aes(x = factor(admitted), fill = factor(admitted))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Count of ER Visits by In Patient Admission Status\",\n    x = \"In Patient Admitted\",\n    y = \"Count\",\n    fill = \"Admitted\"\n  ) +\n  theme_minimal())\n\n\n\n\nggplotly(ggplot(RQ1Viz, aes(x = factor(admitted), fill = factor(mri_ct))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Hospital Admission by Whether MRI CT Was Performed\",\n    x = \"In Patient Admitted\",\n    y = \"Count\",\n    fill = \"MRI CT\"\n  ) +\n  geom_bar(position = \"stack\")+\n  theme_minimal())\n\n\n\n\nggplotly (ggplot(OGData_clean, aes(x = factor(admitted), fill = factor(surgery))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Hospital Admission by Whether Surgery Was Performed\",\n    x = \"Admitted (0 = No, 1 = Yes)\",\n    y = \"Count\",\n    fill = \"Surgery (0 = No, 1 = Yes)\"\n  ) +\n  geom_bar(position = \"stack\")+\n  theme_minimal())\n\n\n\n\n\nRQ 1 1. What predictors can help determine whether an ER visit results in an inpatient admission? Explore a number of predictors such as type of tests, diagnostics, and reason for visit\nhe confusion matrix, and sensitivity/recall for the “admitted” class (how many admitted patients your model correctly identifies).\nADD VARIABLE SELECTION METHOD BEFORE THIS****\n\nRQ1Data &lt;- OGData_clean %&gt;%\n  dplyr:: select(admitted,        \n    mri_ct      ,\n    surgery,\n    xray ,\n    lab_tests ,\n    ekg    ,\n    ultrasound ,\n    mammogram ,\n    vaccination ,\n    rx_given ,\n    related_condition,\n    Insurance)\n\nTrain & Test\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.5.2\n\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\n\nThe following object is masked from 'package:rsample':\n\n    calibration\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(car)\n\n\nset.seed(1)\ntrain_index = createDataPartition(RQ1Data$admitted, p = 0.8, list = FALSE) #createdatapartition ensures that admitted / not admitted are acurately represented in both train and test set*\ntrain_data = RQ1Data[train_index, ]\ntest_data = RQ1Data[-train_index, ]\n\nLogistic Regression\n\nglm_model &lt;- glm(admitted ~ ., data = RQ1Data, family = \"binomial\")\nvif(glm_model) #no multicolinerarity\n\n           mri_ct           surgery              xray         lab_tests \n         1.060226          1.036254          1.058423          1.150643 \n              ekg        ultrasound         mammogram       vaccination \n         1.161988          1.026398          1.006616          1.013955 \n         rx_given related_condition         Insurance \n         1.032644          1.012979          1.059200 \n\n#Train Data to predict admitted with Logistic Regression\nglm.admitted=glm(admitted~.,data=train_data,family=\"binomial\") #the . after ~ shows all variables\nsummary (glm.admitted)\n\n\nCall:\nglm(formula = admitted ~ ., family = \"binomial\", data = train_data)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -1.09992    0.19147  -5.744 9.22e-09 ***\nmri_ct              0.42790    0.10906   3.924 8.72e-05 ***\nsurgery             0.89785    0.18537   4.844 1.28e-06 ***\nxray               -0.03592    0.10341  -0.347    0.728    \nlab_tests           0.82450    0.10913   7.555 4.19e-14 ***\nekg                 0.62813    0.11301   5.558 2.72e-08 ***\nultrasound          0.54345    0.13630   3.987 6.69e-05 ***\nmammogram         -13.87172  238.18570  -0.058    0.954    \nvaccination        -0.18130    0.48603  -0.373    0.709    \nrx_given           -1.30270    0.13127  -9.924  &lt; 2e-16 ***\nrelated_condition   0.96239    0.17494   5.501 3.77e-08 ***\nInsurance          -2.13319    0.11567 -18.442  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3517.9  on 3392  degrees of freedom\nResidual deviance: 2758.8  on 3381  degrees of freedom\nAIC: 2782.8\n\nNumber of Fisher Scoring iterations: 13\n\n# Make predictions on the test set\npredictionsLR = predict(glm.admitted, newdata = test_data, type = \"response\")\n\n# Convert to class labels\nLR_pred &lt;- factor(ifelse(predictionsLR &gt; 0.5, 1, 0), levels = c(0, 1))\nLR_truth &lt;- factor(test_data$admitted, levels = c(0, 1))\n\n# Confusion matrix\nLR_cm &lt;- confusionMatrix(LR_pred, LR_truth) #81.9% accuracy\nLR_cm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 647 124\n         1  29  48\n                                         \n               Accuracy : 0.8196         \n                 95% CI : (0.792, 0.8449)\n    No Information Rate : 0.7972         \n    P-Value [Acc &gt; NIR] : 0.05553        \n                                         \n                  Kappa : 0.2974         \n                                         \n Mcnemar's Test P-Value : 2.974e-14      \n                                         \n            Sensitivity : 0.9571         \n            Specificity : 0.2791         \n         Pos Pred Value : 0.8392         \n         Neg Pred Value : 0.6234         \n             Prevalence : 0.7972         \n         Detection Rate : 0.7630         \n   Detection Prevalence : 0.9092         \n      Balanced Accuracy : 0.6181         \n                                         \n       'Positive' Class : 0              \n                                         \n\n#MSE\nmean((predictionsLR - test_data$admitted)^2) # 0.129\n\n[1] 0.1289928\n\n\nRandom Forest RQ1 - Classification Handles skewed data better\n\nlibrary(randomForest)\nlibrary(caret)\n\n# Train a Random Forest model to predict admitted\nrf_model = randomForest(as.factor(admitted) ~ ., data = train_data, ntree = 500)\nvarImpPlot(rf_model)\n\n\n\n\n\n\n\nrf_model\n\n\nCall:\n randomForest(formula = as.factor(admitted) ~ ., data = train_data,      ntree = 500) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n        OOB estimate of  error rate: 18.16%\nConfusion matrix:\n     0   1 class.error\n0 2585  84  0.03147246\n1  532 192  0.73480663\n\n(plot(rf_model))\n\n\n\n\n\n\n\n\n             OOB          0         1\n  [1,] 0.1835906 0.05648536 0.6254545\n  [2,] 0.1907371 0.05690537 0.6621622\n  [3,] 0.1786423 0.05005056 0.6487985\n  [4,] 0.1818823 0.04993252 0.6596091\n  [5,] 0.1817882 0.05296343 0.6518405\n  [6,] 0.1787180 0.05060241 0.6499261\n  [7,] 0.1840321 0.05492350 0.6575540\n  [8,] 0.1801148 0.05184332 0.6539007\n  [9,] 0.1821996 0.05074399 0.6634078\n [10,] 0.1817640 0.05273141 0.6541667\n [11,] 0.1827893 0.05134013 0.6657420\n [12,] 0.1818720 0.04975499 0.6666667\n [13,] 0.1794796 0.04701015 0.6666667\n [14,] 0.1806909 0.04656403 0.6740331\n [15,] 0.1802892 0.04615385 0.6740331\n [16,] 0.1798349 0.04572714 0.6740331\n [17,] 0.1794872 0.04383664 0.6795580\n [18,] 0.1788977 0.04308730 0.6795580\n [19,] 0.1791925 0.04271263 0.6823204\n [20,] 0.1786030 0.04383664 0.6754144\n [21,] 0.1803714 0.04496066 0.6795580\n [22,] 0.1783083 0.04308730 0.6767956\n [23,] 0.1788977 0.04046459 0.6892265\n [24,] 0.1806661 0.04121394 0.6947514\n [25,] 0.1786030 0.03821656 0.6961326\n [26,] 0.1806661 0.03671787 0.7113260\n [27,] 0.1791925 0.03709254 0.7030387\n [28,] 0.1771294 0.03484451 0.7016575\n [29,] 0.1777188 0.03521918 0.7030387\n [30,] 0.1794872 0.03821656 0.7002762\n [31,] 0.1780136 0.03671787 0.6988950\n [32,] 0.1800766 0.03784189 0.7044199\n [33,] 0.1783083 0.03521918 0.7058011\n [34,] 0.1797819 0.03596853 0.7099448\n [35,] 0.1786030 0.03484451 0.7085635\n [36,] 0.1788977 0.03409517 0.7127072\n [37,] 0.1791925 0.03446984 0.7127072\n [38,] 0.1788977 0.03372049 0.7140884\n [39,] 0.1786030 0.03297115 0.7154696\n [40,] 0.1791925 0.03409517 0.7140884\n [41,] 0.1791925 0.03372049 0.7154696\n [42,] 0.1800766 0.03372049 0.7196133\n [43,] 0.1803714 0.03259648 0.7251381\n [44,] 0.1809608 0.03222181 0.7292818\n [45,] 0.1818450 0.03297115 0.7306630\n [46,] 0.1815503 0.03222181 0.7320442\n [47,] 0.1800766 0.03184713 0.7265193\n [48,] 0.1815503 0.03222181 0.7320442\n [49,] 0.1812555 0.03109779 0.7348066\n [50,] 0.1818450 0.03259648 0.7320442\n [51,] 0.1806661 0.03109779 0.7320442\n [52,] 0.1806661 0.02997377 0.7361878\n [53,] 0.1818450 0.03222181 0.7334254\n [54,] 0.1806661 0.03072312 0.7334254\n [55,] 0.1812555 0.03109779 0.7348066\n [56,] 0.1812555 0.03184713 0.7320442\n [57,] 0.1812555 0.03222181 0.7306630\n [58,] 0.1818450 0.03259648 0.7320442\n [59,] 0.1830239 0.03297115 0.7361878\n [60,] 0.1821397 0.03297115 0.7320442\n [61,] 0.1812555 0.03147246 0.7334254\n [62,] 0.1809608 0.03072312 0.7348066\n [63,] 0.1803714 0.03034845 0.7334254\n [64,] 0.1794872 0.02959910 0.7320442\n [65,] 0.1809608 0.03034845 0.7361878\n [66,] 0.1806661 0.03109779 0.7320442\n [67,] 0.1803714 0.02997377 0.7348066\n [68,] 0.1806661 0.03034845 0.7348066\n [69,] 0.1806661 0.03034845 0.7348066\n [70,] 0.1812555 0.03109779 0.7348066\n [71,] 0.1797819 0.02959910 0.7334254\n [72,] 0.1803714 0.02997377 0.7348066\n [73,] 0.1806661 0.03072312 0.7334254\n [74,] 0.1803714 0.03034845 0.7334254\n [75,] 0.1818450 0.03072312 0.7389503\n [76,] 0.1815503 0.03034845 0.7389503\n [77,] 0.1806661 0.03184713 0.7292818\n [78,] 0.1809608 0.03184713 0.7306630\n [79,] 0.1812555 0.03072312 0.7361878\n [80,] 0.1809608 0.03184713 0.7306630\n [81,] 0.1824344 0.03297115 0.7334254\n [82,] 0.1824344 0.03334582 0.7320442\n [83,] 0.1821397 0.03409517 0.7279006\n [84,] 0.1830239 0.03372049 0.7334254\n [85,] 0.1812555 0.03184713 0.7320442\n [86,] 0.1809608 0.03147246 0.7320442\n [87,] 0.1809608 0.03147246 0.7320442\n [88,] 0.1812555 0.03072312 0.7361878\n [89,] 0.1821397 0.03259648 0.7334254\n [90,] 0.1818450 0.03259648 0.7320442\n [91,] 0.1824344 0.03259648 0.7348066\n [92,] 0.1821397 0.03259648 0.7334254\n [93,] 0.1830239 0.03409517 0.7320442\n [94,] 0.1830239 0.03446984 0.7306630\n [95,] 0.1821397 0.03372049 0.7292818\n [96,] 0.1818450 0.03484451 0.7237569\n [97,] 0.1824344 0.03559386 0.7237569\n [98,] 0.1818450 0.03409517 0.7265193\n [99,] 0.1818450 0.03484451 0.7237569\n[100,] 0.1821397 0.03372049 0.7292818\n[101,] 0.1824344 0.03446984 0.7279006\n[102,] 0.1815503 0.03372049 0.7265193\n[103,] 0.1803714 0.03184713 0.7279006\n[104,] 0.1815503 0.03334582 0.7279006\n[105,] 0.1818450 0.03334582 0.7292818\n[106,] 0.1812555 0.03222181 0.7306630\n[107,] 0.1815503 0.03259648 0.7306630\n[108,] 0.1821397 0.03259648 0.7334254\n[109,] 0.1824344 0.03334582 0.7320442\n[110,] 0.1818450 0.03222181 0.7334254\n[111,] 0.1821397 0.03297115 0.7320442\n[112,] 0.1824344 0.03222181 0.7361878\n[113,] 0.1821397 0.03222181 0.7348066\n[114,] 0.1821397 0.03184713 0.7361878\n[115,] 0.1818450 0.03184713 0.7348066\n[116,] 0.1818450 0.03184713 0.7348066\n[117,] 0.1818450 0.03259648 0.7320442\n[118,] 0.1827291 0.03334582 0.7334254\n[119,] 0.1818450 0.03259648 0.7320442\n[120,] 0.1827291 0.03334582 0.7334254\n[121,] 0.1830239 0.03372049 0.7334254\n[122,] 0.1821397 0.03334582 0.7306630\n[123,] 0.1821397 0.03334582 0.7306630\n[124,] 0.1821397 0.03259648 0.7334254\n[125,] 0.1821397 0.03184713 0.7361878\n[126,] 0.1809608 0.03147246 0.7320442\n[127,] 0.1818450 0.03147246 0.7361878\n[128,] 0.1824344 0.03222181 0.7361878\n[129,] 0.1827291 0.03259648 0.7361878\n[130,] 0.1824344 0.03259648 0.7348066\n[131,] 0.1818450 0.03222181 0.7334254\n[132,] 0.1827291 0.03297115 0.7348066\n[133,] 0.1830239 0.03409517 0.7320442\n[134,] 0.1842028 0.03446984 0.7361878\n[135,] 0.1842028 0.03559386 0.7320442\n[136,] 0.1830239 0.03484451 0.7292818\n[137,] 0.1836133 0.03521918 0.7306630\n[138,] 0.1830239 0.03446984 0.7306630\n[139,] 0.1836133 0.03484451 0.7320442\n[140,] 0.1827291 0.03409517 0.7306630\n[141,] 0.1824344 0.03372049 0.7306630\n[142,] 0.1824344 0.03297115 0.7334254\n[143,] 0.1821397 0.03297115 0.7320442\n[144,] 0.1821397 0.03297115 0.7320442\n[145,] 0.1824344 0.03297115 0.7334254\n[146,] 0.1824344 0.03259648 0.7348066\n[147,] 0.1821397 0.03259648 0.7334254\n[148,] 0.1827291 0.03334582 0.7334254\n[149,] 0.1830239 0.03372049 0.7334254\n[150,] 0.1821397 0.03259648 0.7334254\n[151,] 0.1830239 0.03334582 0.7348066\n[152,] 0.1824344 0.03259648 0.7348066\n[153,] 0.1824344 0.03259648 0.7348066\n[154,] 0.1827291 0.03334582 0.7334254\n[155,] 0.1815503 0.03297115 0.7292818\n[156,] 0.1821397 0.03372049 0.7292818\n[157,] 0.1827291 0.03409517 0.7306630\n[158,] 0.1815503 0.03334582 0.7279006\n[159,] 0.1821397 0.03297115 0.7320442\n[160,] 0.1815503 0.03259648 0.7306630\n[161,] 0.1818450 0.03297115 0.7306630\n[162,] 0.1815503 0.03259648 0.7306630\n[163,] 0.1818450 0.03297115 0.7306630\n[164,] 0.1821397 0.03222181 0.7348066\n[165,] 0.1821397 0.03222181 0.7348066\n[166,] 0.1809608 0.03072312 0.7348066\n[167,] 0.1815503 0.03184713 0.7334254\n[168,] 0.1815503 0.03259648 0.7306630\n[169,] 0.1818450 0.03259648 0.7320442\n[170,] 0.1818450 0.03297115 0.7306630\n[171,] 0.1818450 0.03222181 0.7334254\n[172,] 0.1812555 0.03184713 0.7320442\n[173,] 0.1806661 0.03109779 0.7320442\n[174,] 0.1815503 0.03184713 0.7334254\n[175,] 0.1806661 0.03072312 0.7334254\n[176,] 0.1812555 0.03147246 0.7334254\n[177,] 0.1803714 0.02997377 0.7348066\n[178,] 0.1806661 0.03034845 0.7348066\n[179,] 0.1806661 0.03109779 0.7320442\n[180,] 0.1803714 0.03109779 0.7306630\n[181,] 0.1800766 0.03034845 0.7320442\n[182,] 0.1806661 0.03034845 0.7348066\n[183,] 0.1803714 0.03034845 0.7334254\n[184,] 0.1815503 0.03034845 0.7389503\n[185,] 0.1803714 0.02922443 0.7375691\n[186,] 0.1800766 0.02959910 0.7348066\n[187,] 0.1809608 0.02997377 0.7375691\n[188,] 0.1803714 0.02959910 0.7361878\n[189,] 0.1803714 0.02959910 0.7361878\n[190,] 0.1800766 0.02922443 0.7361878\n[191,] 0.1797819 0.02884976 0.7361878\n[192,] 0.1803714 0.02959910 0.7361878\n[193,] 0.1803714 0.02997377 0.7348066\n[194,] 0.1797819 0.02959910 0.7334254\n[195,] 0.1800766 0.02922443 0.7361878\n[196,] 0.1803714 0.02922443 0.7375691\n[197,] 0.1812555 0.02922443 0.7417127\n[198,] 0.1806661 0.02922443 0.7389503\n[199,] 0.1806661 0.02922443 0.7389503\n[200,] 0.1803714 0.02884976 0.7389503\n[201,] 0.1800766 0.02847508 0.7389503\n[202,] 0.1803714 0.02847508 0.7403315\n[203,] 0.1803714 0.02884976 0.7389503\n[204,] 0.1800766 0.02847508 0.7389503\n[205,] 0.1800766 0.02847508 0.7389503\n[206,] 0.1797819 0.02772574 0.7403315\n[207,] 0.1797819 0.02772574 0.7403315\n[208,] 0.1800766 0.02735107 0.7430939\n[209,] 0.1797819 0.02735107 0.7417127\n[210,] 0.1794872 0.02735107 0.7403315\n[211,] 0.1797819 0.02735107 0.7417127\n[212,] 0.1800766 0.02772574 0.7417127\n[213,] 0.1809608 0.02847508 0.7430939\n[214,] 0.1812555 0.02922443 0.7417127\n[215,] 0.1815503 0.02959910 0.7417127\n[216,] 0.1809608 0.02884976 0.7417127\n[217,] 0.1803714 0.02959910 0.7361878\n[218,] 0.1800766 0.02884976 0.7375691\n[219,] 0.1800766 0.02884976 0.7375691\n[220,] 0.1803714 0.02959910 0.7361878\n[221,] 0.1797819 0.02847508 0.7375691\n[222,] 0.1800766 0.02884976 0.7375691\n[223,] 0.1800766 0.02884976 0.7375691\n[224,] 0.1803714 0.02922443 0.7375691\n[225,] 0.1806661 0.02959910 0.7375691\n[226,] 0.1806661 0.02959910 0.7375691\n[227,] 0.1809608 0.02997377 0.7375691\n[228,] 0.1800766 0.02884976 0.7375691\n[229,] 0.1803714 0.02959910 0.7361878\n[230,] 0.1815503 0.02997377 0.7403315\n[231,] 0.1809608 0.02922443 0.7403315\n[232,] 0.1812555 0.02959910 0.7403315\n[233,] 0.1812555 0.02959910 0.7403315\n[234,] 0.1812555 0.02997377 0.7389503\n[235,] 0.1815503 0.03034845 0.7389503\n[236,] 0.1803714 0.02959910 0.7361878\n[237,] 0.1809608 0.02997377 0.7375691\n[238,] 0.1812555 0.02997377 0.7389503\n[239,] 0.1809608 0.03034845 0.7361878\n[240,] 0.1809608 0.03072312 0.7348066\n[241,] 0.1815503 0.03109779 0.7361878\n[242,] 0.1806661 0.03072312 0.7334254\n[243,] 0.1815503 0.03072312 0.7375691\n[244,] 0.1800766 0.02922443 0.7361878\n[245,] 0.1806661 0.02997377 0.7361878\n[246,] 0.1815503 0.03072312 0.7375691\n[247,] 0.1806661 0.02997377 0.7361878\n[248,] 0.1806661 0.02959910 0.7375691\n[249,] 0.1806661 0.02959910 0.7375691\n[250,] 0.1812555 0.02997377 0.7389503\n[251,] 0.1806661 0.02922443 0.7389503\n[252,] 0.1815503 0.02997377 0.7403315\n[253,] 0.1815503 0.03034845 0.7389503\n[254,] 0.1812555 0.02959910 0.7403315\n[255,] 0.1812555 0.02959910 0.7403315\n[256,] 0.1809608 0.02959910 0.7389503\n[257,] 0.1815503 0.02997377 0.7403315\n[258,] 0.1815503 0.02997377 0.7403315\n[259,] 0.1809608 0.02959910 0.7389503\n[260,] 0.1803714 0.02922443 0.7375691\n[261,] 0.1806661 0.02922443 0.7389503\n[262,] 0.1812555 0.02959910 0.7403315\n[263,] 0.1806661 0.02922443 0.7389503\n[264,] 0.1797819 0.02810041 0.7389503\n[265,] 0.1803714 0.02884976 0.7389503\n[266,] 0.1806661 0.02959910 0.7375691\n[267,] 0.1806661 0.02922443 0.7389503\n[268,] 0.1803714 0.02884976 0.7389503\n[269,] 0.1800766 0.02847508 0.7389503\n[270,] 0.1803714 0.02922443 0.7375691\n[271,] 0.1800766 0.02884976 0.7375691\n[272,] 0.1818450 0.02997377 0.7417127\n[273,] 0.1821397 0.02997377 0.7430939\n[274,] 0.1818450 0.02997377 0.7417127\n[275,] 0.1812555 0.02997377 0.7389503\n[276,] 0.1815503 0.02997377 0.7403315\n[277,] 0.1818450 0.02997377 0.7417127\n[278,] 0.1821397 0.03034845 0.7417127\n[279,] 0.1818450 0.03034845 0.7403315\n[280,] 0.1818450 0.02997377 0.7417127\n[281,] 0.1812555 0.02997377 0.7389503\n[282,] 0.1812555 0.02997377 0.7389503\n[283,] 0.1809608 0.03034845 0.7361878\n[284,] 0.1812555 0.03034845 0.7375691\n[285,] 0.1809608 0.03034845 0.7361878\n[286,] 0.1806661 0.03034845 0.7348066\n[287,] 0.1809608 0.03034845 0.7361878\n[288,] 0.1803714 0.02997377 0.7348066\n[289,] 0.1800766 0.02997377 0.7334254\n[290,] 0.1803714 0.02997377 0.7348066\n[291,] 0.1803714 0.03034845 0.7334254\n[292,] 0.1800766 0.03034845 0.7320442\n[293,] 0.1797819 0.03072312 0.7292818\n[294,] 0.1803714 0.02997377 0.7348066\n[295,] 0.1794872 0.02997377 0.7306630\n[296,] 0.1800766 0.03072312 0.7306630\n[297,] 0.1800766 0.03072312 0.7306630\n[298,] 0.1794872 0.03072312 0.7279006\n[299,] 0.1797819 0.03147246 0.7265193\n[300,] 0.1791925 0.03109779 0.7251381\n[301,] 0.1797819 0.03109779 0.7279006\n[302,] 0.1794872 0.03072312 0.7279006\n[303,] 0.1791925 0.03072312 0.7265193\n[304,] 0.1791925 0.03034845 0.7279006\n[305,] 0.1794872 0.03034845 0.7292818\n[306,] 0.1794872 0.03072312 0.7279006\n[307,] 0.1786030 0.02997377 0.7265193\n[308,] 0.1786030 0.03034845 0.7251381\n[309,] 0.1788977 0.03034845 0.7265193\n[310,] 0.1791925 0.03072312 0.7265193\n[311,] 0.1797819 0.03109779 0.7279006\n[312,] 0.1797819 0.03147246 0.7265193\n[313,] 0.1794872 0.03109779 0.7265193\n[314,] 0.1803714 0.03184713 0.7279006\n[315,] 0.1797819 0.03147246 0.7265193\n[316,] 0.1803714 0.03184713 0.7279006\n[317,] 0.1803714 0.03184713 0.7279006\n[318,] 0.1797819 0.03147246 0.7265193\n[319,] 0.1800766 0.03147246 0.7279006\n[320,] 0.1794872 0.03147246 0.7251381\n[321,] 0.1797819 0.03147246 0.7265193\n[322,] 0.1797819 0.03109779 0.7279006\n[323,] 0.1797819 0.03109779 0.7279006\n[324,] 0.1800766 0.03109779 0.7292818\n[325,] 0.1797819 0.03109779 0.7279006\n[326,] 0.1791925 0.03109779 0.7251381\n[327,] 0.1797819 0.03109779 0.7279006\n[328,] 0.1800766 0.03147246 0.7279006\n[329,] 0.1794872 0.03147246 0.7251381\n[330,] 0.1800766 0.03184713 0.7265193\n[331,] 0.1797819 0.03147246 0.7265193\n[332,] 0.1791925 0.03109779 0.7251381\n[333,] 0.1794872 0.03109779 0.7265193\n[334,] 0.1797819 0.03147246 0.7265193\n[335,] 0.1797819 0.03147246 0.7265193\n[336,] 0.1800766 0.03109779 0.7292818\n[337,] 0.1797819 0.03147246 0.7265193\n[338,] 0.1797819 0.03147246 0.7265193\n[339,] 0.1800766 0.03184713 0.7265193\n[340,] 0.1797819 0.03184713 0.7251381\n[341,] 0.1794872 0.03147246 0.7251381\n[342,] 0.1791925 0.03072312 0.7265193\n[343,] 0.1788977 0.03034845 0.7265193\n[344,] 0.1791925 0.03034845 0.7279006\n[345,] 0.1797819 0.03072312 0.7292818\n[346,] 0.1794872 0.03109779 0.7265193\n[347,] 0.1797819 0.03109779 0.7279006\n[348,] 0.1794872 0.03072312 0.7279006\n[349,] 0.1794872 0.03109779 0.7265193\n[350,] 0.1800766 0.03147246 0.7279006\n[351,] 0.1800766 0.03147246 0.7279006\n[352,] 0.1806661 0.03184713 0.7292818\n[353,] 0.1806661 0.03147246 0.7306630\n[354,] 0.1803714 0.03147246 0.7292818\n[355,] 0.1803714 0.03109779 0.7306630\n[356,] 0.1803714 0.03147246 0.7292818\n[357,] 0.1806661 0.03147246 0.7306630\n[358,] 0.1803714 0.03109779 0.7306630\n[359,] 0.1812555 0.03222181 0.7306630\n[360,] 0.1803714 0.03147246 0.7292818\n[361,] 0.1806661 0.03147246 0.7306630\n[362,] 0.1803714 0.03109779 0.7306630\n[363,] 0.1809608 0.03147246 0.7320442\n[364,] 0.1809608 0.03147246 0.7320442\n[365,] 0.1806661 0.03147246 0.7306630\n[366,] 0.1803714 0.03147246 0.7292818\n[367,] 0.1800766 0.03147246 0.7279006\n[368,] 0.1803714 0.03147246 0.7292818\n[369,] 0.1800766 0.03109779 0.7292818\n[370,] 0.1806661 0.03147246 0.7306630\n[371,] 0.1806661 0.03147246 0.7306630\n[372,] 0.1806661 0.03147246 0.7306630\n[373,] 0.1803714 0.03109779 0.7306630\n[374,] 0.1803714 0.03072312 0.7320442\n[375,] 0.1800766 0.03072312 0.7306630\n[376,] 0.1806661 0.03109779 0.7320442\n[377,] 0.1803714 0.03109779 0.7306630\n[378,] 0.1803714 0.03109779 0.7306630\n[379,] 0.1806661 0.03147246 0.7306630\n[380,] 0.1809608 0.03184713 0.7306630\n[381,] 0.1806661 0.03147246 0.7306630\n[382,] 0.1803714 0.03109779 0.7306630\n[383,] 0.1797819 0.03034845 0.7306630\n[384,] 0.1800766 0.03034845 0.7320442\n[385,] 0.1800766 0.03072312 0.7306630\n[386,] 0.1803714 0.03109779 0.7306630\n[387,] 0.1803714 0.03072312 0.7320442\n[388,] 0.1809608 0.03147246 0.7320442\n[389,] 0.1806661 0.03109779 0.7320442\n[390,] 0.1809608 0.03109779 0.7334254\n[391,] 0.1800766 0.03109779 0.7292818\n[392,] 0.1806661 0.03147246 0.7306630\n[393,] 0.1806661 0.03147246 0.7306630\n[394,] 0.1809608 0.03147246 0.7320442\n[395,] 0.1815503 0.03147246 0.7348066\n[396,] 0.1815503 0.03184713 0.7334254\n[397,] 0.1812555 0.03184713 0.7320442\n[398,] 0.1809608 0.03147246 0.7320442\n[399,] 0.1809608 0.03147246 0.7320442\n[400,] 0.1812555 0.03147246 0.7334254\n[401,] 0.1809608 0.03147246 0.7320442\n[402,] 0.1818450 0.03184713 0.7348066\n[403,] 0.1818450 0.03184713 0.7348066\n[404,] 0.1812555 0.03147246 0.7334254\n[405,] 0.1815503 0.03184713 0.7334254\n[406,] 0.1818450 0.03147246 0.7361878\n[407,] 0.1815503 0.03184713 0.7334254\n[408,] 0.1815503 0.03184713 0.7334254\n[409,] 0.1815503 0.03184713 0.7334254\n[410,] 0.1821397 0.03222181 0.7348066\n[411,] 0.1824344 0.03259648 0.7348066\n[412,] 0.1821397 0.03259648 0.7334254\n[413,] 0.1812555 0.03222181 0.7306630\n[414,] 0.1821397 0.03259648 0.7334254\n[415,] 0.1821397 0.03297115 0.7320442\n[416,] 0.1818450 0.03259648 0.7320442\n[417,] 0.1818450 0.03259648 0.7320442\n[418,] 0.1815503 0.03259648 0.7306630\n[419,] 0.1818450 0.03259648 0.7320442\n[420,] 0.1818450 0.03259648 0.7320442\n[421,] 0.1821397 0.03334582 0.7306630\n[422,] 0.1818450 0.03297115 0.7306630\n[423,] 0.1824344 0.03372049 0.7306630\n[424,] 0.1818450 0.03297115 0.7306630\n[425,] 0.1824344 0.03334582 0.7320442\n[426,] 0.1818450 0.03259648 0.7320442\n[427,] 0.1815503 0.03222181 0.7320442\n[428,] 0.1815503 0.03259648 0.7306630\n[429,] 0.1818450 0.03334582 0.7292818\n[430,] 0.1818450 0.03297115 0.7306630\n[431,] 0.1818450 0.03297115 0.7306630\n[432,] 0.1809608 0.03184713 0.7306630\n[433,] 0.1809608 0.03184713 0.7306630\n[434,] 0.1818450 0.03259648 0.7320442\n[435,] 0.1821397 0.03334582 0.7306630\n[436,] 0.1815503 0.03222181 0.7320442\n[437,] 0.1821397 0.03297115 0.7320442\n[438,] 0.1821397 0.03259648 0.7334254\n[439,] 0.1818450 0.03184713 0.7348066\n[440,] 0.1818450 0.03222181 0.7334254\n[441,] 0.1815503 0.03222181 0.7320442\n[442,] 0.1821397 0.03297115 0.7320442\n[443,] 0.1824344 0.03334582 0.7320442\n[444,] 0.1827291 0.03334582 0.7334254\n[445,] 0.1818450 0.03222181 0.7334254\n[446,] 0.1818450 0.03222181 0.7334254\n[447,] 0.1818450 0.03222181 0.7334254\n[448,] 0.1821397 0.03222181 0.7348066\n[449,] 0.1821397 0.03222181 0.7348066\n[450,] 0.1827291 0.03297115 0.7348066\n[451,] 0.1827291 0.03297115 0.7348066\n[452,] 0.1827291 0.03259648 0.7361878\n[453,] 0.1830239 0.03297115 0.7361878\n[454,] 0.1827291 0.03259648 0.7361878\n[455,] 0.1827291 0.03222181 0.7375691\n[456,] 0.1827291 0.03184713 0.7389503\n[457,] 0.1827291 0.03184713 0.7389503\n[458,] 0.1824344 0.03147246 0.7389503\n[459,] 0.1824344 0.03147246 0.7389503\n[460,] 0.1821397 0.03147246 0.7375691\n[461,] 0.1821397 0.03147246 0.7375691\n[462,] 0.1821397 0.03147246 0.7375691\n[463,] 0.1821397 0.03147246 0.7375691\n[464,] 0.1815503 0.03147246 0.7348066\n[465,] 0.1821397 0.03184713 0.7361878\n[466,] 0.1818450 0.03147246 0.7361878\n[467,] 0.1824344 0.03184713 0.7375691\n[468,] 0.1821397 0.03147246 0.7375691\n[469,] 0.1821397 0.03147246 0.7375691\n[470,] 0.1815503 0.03072312 0.7375691\n[471,] 0.1815503 0.03034845 0.7389503\n[472,] 0.1809608 0.02997377 0.7375691\n[473,] 0.1818450 0.03109779 0.7375691\n[474,] 0.1821397 0.03184713 0.7361878\n[475,] 0.1821397 0.03147246 0.7375691\n[476,] 0.1818450 0.03147246 0.7361878\n[477,] 0.1812555 0.03072312 0.7361878\n[478,] 0.1815503 0.03109779 0.7361878\n[479,] 0.1821397 0.03147246 0.7375691\n[480,] 0.1812555 0.03034845 0.7375691\n[481,] 0.1815503 0.03109779 0.7361878\n[482,] 0.1815503 0.03072312 0.7375691\n[483,] 0.1815503 0.03072312 0.7375691\n[484,] 0.1812555 0.03072312 0.7361878\n[485,] 0.1818450 0.03147246 0.7361878\n[486,] 0.1821397 0.03147246 0.7375691\n[487,] 0.1809608 0.03034845 0.7361878\n[488,] 0.1815503 0.03109779 0.7361878\n[489,] 0.1818450 0.03109779 0.7375691\n[490,] 0.1815503 0.03147246 0.7348066\n[491,] 0.1818450 0.03147246 0.7361878\n[492,] 0.1818450 0.03147246 0.7361878\n[493,] 0.1815503 0.03109779 0.7361878\n[494,] 0.1812555 0.03072312 0.7361878\n[495,] 0.1812555 0.03109779 0.7348066\n[496,] 0.1818450 0.03184713 0.7348066\n[497,] 0.1812555 0.03109779 0.7348066\n[498,] 0.1815503 0.03109779 0.7361878\n[499,] 0.1815503 0.03147246 0.7348066\n[500,] 0.1815503 0.03147246 0.7348066\n\nsummary (rf_model)\n\n                Length Class  Mode     \ncall               4   -none- call     \ntype               1   -none- character\npredicted       3393   factor numeric  \nerr.rate        1500   -none- numeric  \nconfusion          6   -none- numeric  \nvotes           6786   matrix numeric  \noob.times       3393   -none- numeric  \nclasses            2   -none- character\nimportance        11   -none- numeric  \nimportanceSD       0   -none- NULL     \nlocalImportance    0   -none- NULL     \nproximity          0   -none- NULL     \nntree              1   -none- numeric  \nmtry               1   -none- numeric  \nforest            14   -none- list     \ny               3393   factor numeric  \ntest               0   -none- NULL     \ninbag              0   -none- NULL     \nterms              3   terms  call     \n\n# Make predictions on the test set\npredictions = predict(rf_model, newdata = test_data)\n\n#model performance\n#rf_model$mse\n#which.min(mse) #362 trees used \n\nmean(predictions == test_data$admitted) #81.7\n\n[1] 0.817217\n\nconfusionMatrix(predictions, as.factor(test_data$admitted)) #confusion matrix\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 653 132\n         1  23  40\n                                          \n               Accuracy : 0.8172          \n                 95% CI : (0.7895, 0.8427)\n    No Information Rate : 0.7972          \n    P-Value [Acc &gt; NIR] : 0.07809         \n                                          \n                  Kappa : 0.2599          \n                                          \n Mcnemar's Test P-Value : &lt; 2e-16         \n                                          \n            Sensitivity : 0.9660          \n            Specificity : 0.2326          \n         Pos Pred Value : 0.8318          \n         Neg Pred Value : 0.6349          \n             Prevalence : 0.7972          \n         Detection Rate : 0.7700          \n   Detection Prevalence : 0.9257          \n      Balanced Accuracy : 0.5993          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\n\n\nResearch Question 2: Which characteristics of an ER visit are most strongly associated with the highest total ER expenditure?\nLibrary Download\n\nlibrary(tidymodels)\nlibrary(glmnet)\nlibrary(xgboost)\nlibrary(vip)\nlibrary(haven)\nlibrary(ranger)\nlibrary(randomForest)\nlibrary(tree)\nlibrary(ISLR)\nlibrary(dplyr)\nlibrary (plotly)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(caret)\n\nAdding in Insurance Information\n\n#Cleaning Data to find Insurance v No Insurance\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(Insurance = case_when(\n    (private_fac &gt; 0  |  private_doc &gt; 0 | medicaid_fac &gt; 0 | medicaid_doc &gt; 0 | medicare_fac &gt; 0 | medicare_doc &gt; 0) ~ \"1\",\n    TRUE ~ \"0\"\n  ))\n\nOGData_clean$Insurance &lt;- as.numeric(OGData_clean$Insurance)\n\nCleaning up binary data Clean More Data - Deal with 95 & 1&2 to 0,1 remove -8 dont know variables 1 is yes 2 is no - changing to 0,1 - no - 0 yes 1\n\nyesno_vars &lt;- c(\n  \"mri_ct\", \"surgery\", \"xray\", \"lab_tests\", \"ekg\",\n  \"ultrasound\", \"mammogram\", \"vaccination\", \"rx_given\",\n  \"related_condition\")\n\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(across(all_of(yesno_vars), ~ ifelse(. == 1, 1, 0))) #keeps all the 1's and replaces the rest with 0\n\n#cleaning admitted inpatient for RQ1\nOGData_clean$admitted &lt;- ifelse(OGData_clean$admitted == \"-1\", 0, 1) #-1 not admitted - changing to 0;; recoding 1 to be admitted\ntable(OGData_clean$admitted) #not admitted 3345; admitted:896\n\n\n   1 \n4241 \n\n\nRQ2 Question 2. Which characteristics of an ER visit (specific tests, procedures, or diagnoses) are most strongly associated with the highest total ER expenditures? A lot of outliers\nMaking Dataset for RQ2\n\nRQ2Data &lt;- OGData_clean %&gt;%\n  dplyr:: select( admitted,       \n    mri_ct      ,\n    surgery,\n    xray ,\n    lab_tests ,\n    ekg    ,\n    ultrasound ,\n    mammogram ,\n    vaccination ,\n    rx_given ,\n    related_condition,\n    total_cost)\n\nExploring Dataset / Characteristics\n\nsummary (RQ2Data$total_cost) #Median - 578, Mean 1227.9 Max: 195314.5\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n     0.0    206.7    578.2   1227.9   1272.0 195314.5 \n\nsum(RQ2Data$total_cost == 0, na.rm = TRUE) #367 cases with 0 out of pocket cost\n\n[1] 367\n\nsum(RQ2Data$total_cost != 0, na.rm = TRUE) #3874 cases with more than 0 out of pocket\n\n[1] 3874\n\nRQ2DataViz &lt;- RQ2Data %&gt;%\nmutate(cost_group = ifelse(total_cost == 0, \"0\", \"&gt;0\"))\n\n#Bar Chart showing majority has more than $0 Costs\nggplotly (ggplot(RQ2DataViz, aes(x = cost_group, fill = cost_group)) +\ngeom_bar() +\nxlab(\"Total Cost\") +\nylab(\"Count\") +\nggtitle(\"Count of 0 vs &gt;0 Total Cost\") +\ntheme_minimal())\n\n\n\n\n#Boxplot of Total Cost\nggplotly(ggplot(RQ2Data, aes(x = \"\", y = total_cost)) +\ngeom_boxplot(fill = \"steelblue\")\n  + # focus on main range\n  ggtitle(\"Total Cost Distribution of ER Visits\") +\n  xlab(\"Total Cost ($)\") +\n  ylab(\"Count\")+\ncoord_cartesian(ylim = c(0, 5000))) #this was able to show the box because of so many outliers / noise\n\n\n\n\n#showing the distribution of total cost\nggplot(RQ2Data, aes(x = total_cost)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", alpha = 0.7) +\n  scale_x_continuous(limits = c(0, 5000)) + # focus on main range\n  ggtitle(\"Total Cost Distribution of ER Visits\") +\n  xlab(\"Total Cost ($)\") +\n  ylab(\"Count\") +\n  theme_minimal() \n\nWarning: Removed 143 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nRandom Forest Model because a lot of outliers\n\nlibrary(randomForest)\nlibrary(caret)\n\nset.seed(1)\ntrain_index1 = createDataPartition(RQ2Data$total_cost, p = 0.7, list = FALSE) \ntrain_data1 = RQ2Data[train_index1, ]\ntest_data1 = RQ2Data[-train_index1, ]\n\n\nrf.RQ2=randomForest(total_cost~.,data=train_data1, ntree = 500, importance = TRUE)\nvarImpPlot(rf.RQ2)\n\n\n\n\n\n\n\nrf.RQ2\n\n\nCall:\n randomForest(formula = total_cost ~ ., data = train_data1, ntree = 500,      importance = TRUE) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n          Mean of squared residuals: 18790068\n                    % Var explained: -1.74\n\nplot(rf.RQ2)\n\n\n\n\n\n\n\nimportance(rf.RQ2)\n\n                      %IncMSE IncNodePurity\nadmitted            0.0000000             0\nmri_ct             -7.7846562     686840954\nsurgery            -2.4621831     335768047\nxray               -7.8670960     415315607\nlab_tests          -7.7045082     214092768\nekg               -11.4278188     420924965\nultrasound        -12.4757435     728741962\nmammogram          -0.7349283      29174336\nvaccination         4.2598684      61253195\nrx_given           -7.3649995     309750976\nrelated_condition  -4.4996245      61669431\n\nsummary (rf.RQ2)\n\n                Length Class  Mode     \ncall               5   -none- call     \ntype               1   -none- character\npredicted       2970   -none- numeric  \nmse              500   -none- numeric  \nrsq              500   -none- numeric  \noob.times       2970   -none- numeric  \nimportance        22   -none- numeric  \nimportanceSD      11   -none- numeric  \nlocalImportance    0   -none- NULL     \nproximity          0   -none- NULL     \nntree              1   -none- numeric  \nmtry               1   -none- numeric  \nforest            11   -none- list     \ncoefs              0   -none- NULL     \ny               2970   -none- numeric  \ntest               0   -none- NULL     \ninbag              0   -none- NULL     \nterms              3   terms  call     \n\n#REGRESSION ANALYSIS FOR CONTINUOUS VARIABLE\n# Make predictions on the test set\npredictionsRQ2 = predict(rf.RQ2, newdata = test_data1)\n\n# Evaluate the model performance\n# Regression metrics\nrmse &lt;- sqrt(mean((test_data1$total_cost - predictionsRQ2)^2)) #RMSE 997.89\nmae  &lt;- mean(abs(test_data1$total_cost - predictionsRQ2)) #MAE: 243.08\nrsq  &lt;- cor(test_data1$total_cost, predictionsRQ2)^2 #RSQLM: 0.97\n\nMultiple Linear Regression Model\n\nfit = lm(total_cost ~ ., data = train_data1)\npred_lm = predict(fit, newdata = test_data1)\n\nsummary(fit)\n\n\nCall:\nlm(formula = total_cost ~ ., data = train_data1)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -2768   -860   -466    140 192804 \n\nCoefficients: (1 not defined because of singularities)\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         805.95     229.23   3.516 0.000445 ***\nadmitted                NA         NA      NA       NA    \nmri_ct              828.17     190.22   4.354 1.38e-05 ***\nsurgery             257.15     343.81   0.748 0.454558    \nxray                 76.41     167.75   0.456 0.648767    \nlab_tests           140.77     169.19   0.832 0.405476    \nekg                 243.77     209.98   1.161 0.245757    \nultrasound          502.06     253.63   1.980 0.047850 *  \nmammogram          -395.80    1920.73  -0.206 0.836754    \nvaccination        -575.54     646.04  -0.891 0.373072    \nrx_given            189.97     174.42   1.089 0.276171    \nrelated_condition   -86.66     229.00  -0.378 0.705140    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4280 on 2959 degrees of freedom\nMultiple R-squared:  0.01195,   Adjusted R-squared:  0.008614 \nF-statistic:  3.58 on 10 and 2959 DF,  p-value: 9.746e-05\n\nsqrt(mean((test_data1$total_cost - pred_lm)^2)) #RMSE 3689.77\n\n[1] 3952.412\n\nmean(abs(test_data1$total_cost - pred_lm)) #MAE: 1147.58\n\n[1] 1253.426\n\ncor(test_data1$total_cost, pred_lm)^2 #RSQLM:0.1324599\n\n[1] 0.005716896\n\n\n\n\nResearch Question 3: What impacts the number of tests and procedures a patient gets done in the ER?\nCleaning up binary data Clean More Data - Deal with 95 & 1&2 to 0,1 remove -8 dont know variables 1 is yes 2 is no - changing to 0,1 - no - 0 yes 1\n\nyesno_vars &lt;- c(\n  \"mri_ct\", \"surgery\", \"xray\", \"lab_tests\", \"ekg\",\n  \"ultrasound\", \"mammogram\", \"vaccination\", \"rx_given\",\n  \"related_condition\")\n\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(across(all_of(yesno_vars), ~ ifelse(. == 1, 1, 0))) #keeps all the 1's and replaces the rest with 0\n\n#cleaning admitted inpatient for RQ1\nOGData_clean$admitted &lt;- ifelse(OGData_clean$admitted == \"-1\", 0, 1) #-1 not admitted - changing to 0;; recoding 1 to be admitted\n\nAdding in Insurance Information\n\n#Cleaning Data to find Insurance v No Insurance\nRQ3Data &lt;- OGData_clean %&gt;%\n  mutate(Insurance = case_when(\n    (private_fac &gt; 0  |  private_doc &gt; 0 | medicaid_fac &gt; 0 | medicaid_doc &gt; 0 | medicare_fac &gt; 0 | medicare_doc &gt; 0) ~ \"1\",\n    TRUE ~ \"0\"\n  ))\n\nRQ3Data$Insurance &lt;- as.numeric(RQ3Data$Insurance)\n\n#Count the total number of tests / procedures done for pt\ntest_vars &lt;- c(\"mri_ct\", \"surgery\", \"xray\", \"lab_tests\", \n               \"ekg\", \"ultrasound\", \"mammogram\", \n               \"vaccination\", \"rx_given\", \"related_condition\")\n\n# Create new variable\nRQ3Data &lt;- RQ3Data %&gt;%\n  rowwise() %&gt;%\n  mutate(total_tests = sum(c_across(all_of(test_vars)), na.rm = TRUE)) %&gt;%\n  ungroup()\n\nRQ3Data&lt;- RQ3Data %&gt;%\n  dplyr:: select(Insurance, total_tests,person_id) #added ID or dupersid to merge later\n\nMerging New Dataset\n\nlibrary(haven)\nlibrary(dplyr)\n\n#dowloaded the SAS File & filtering only the variables needed\nMergeDataDemo &lt;- read_sas(\"C:/Users/diane/Downloads/h251.sas7bdat\") %&gt;%\n  dplyr::select(DUPERSID, SEX,#1 male, 2 female\n                POVCAT23) #1 is low income to 5 high\n\nRQ3Data &lt;- RQ3Data %&gt;%\n  mutate(person_id = as.numeric(person_id))\n\nMergeDataDemo &lt;- MergeDataDemo %&gt;%\n  mutate(DUPERSID = as.numeric(DUPERSID))\n\nMergedDataRQ3 &lt;- RQ3Data %&gt;%\n  left_join(MergeDataDemo, by = c(\"person_id\" = \"DUPERSID\"))\n\nMergedDataRQ3 &lt;- MergedDataRQ3 %&gt;%\n   dplyr::select(-person_id)#no need after merge\n\n#changing sex to 0,1 (male 0 female 1)\nMergedDataRQ3 &lt;- MergedDataRQ3 %&gt;%\n  mutate(SEX = ifelse(SEX == 1, 0,\n                      ifelse(SEX == 2, 1, NA)))\n\n#Missing Data\nsum(is.na(MergedDataRQ3)) #no missing\n\n[1] 0\n\n\nData Visualization\n\nlibrary (ggplot2)\nlibrary (plotly)\n#making the visualization show yes / no\nRQ3Viz &lt;- MergedDataRQ3 %&gt;%\n  mutate(Insurance = factor(Insurance,\n                            levels = c(0, 1),\n                            labels = c(\"No\", \"Yes\")))\n\n\nggplotly(ggplot(RQ3Viz, aes(x = factor(POVCAT23), fill = Insurance)) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"Poverty Category\", y = \"Count\",\n       title = \"Poverty Category by Insurance Status\"))\n\n\n\n\n#high income has a higher no insurance rate than the very low\n\n#table of insurance & poverty category\ntable(RQ3Viz$Insurance, RQ3Viz$POVCAT23)\n\n     \n        1   2   3   4   5\n  No  144  34  77 211 178\n  Yes 833 276 581 913 994\n\nprop.table(table(RQ3Viz$Insurance, RQ3Viz$POVCAT23), margin = 1) * 100 #proporations\n\n     \n              1         2         3         4         5\n  No  22.360248  5.279503 11.956522 32.763975 27.639752\n  Yes 23.158187  7.673061 16.152349 25.382263 27.634140\n\ntable (RQ3Viz$Insurance)# Imbalanced data 644 No insurance 3597 Insurance\n\n\n  No  Yes \n 644 3597 \n\ntable (RQ3Viz$total_tests)\n\n\n   0    1    2    3    4    5    6    7    8 \n 145  735 1230 1050  653  306   98   19    5 \n\nstr (RQ3Viz) #all numerical\n\ntibble [4,241 × 4] (S3: tbl_df/tbl/data.frame)\n $ Insurance  : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 2 2 2 2 ...\n $ total_tests: num [1:4241] 3 3 2 5 3 3 3 2 3 3 ...\n $ SEX        : num [1:4241] 0 1 0 0 0 1 1 1 1 0 ...\n $ POVCAT23   : num [1:4241] 1 5 3 3 5 3 5 5 4 4 ...\n  ..- attr(*, \"label\")= chr \"FAMILY INC AS % OF POVERTY LINE - CATEGORICAL\"\n\nprop.table(table(RQ3Viz$Insurance, RQ3Viz$total_tests), margin = 1) * 100\n\n     \n                0           1           2           3           4           5\n  No   2.95031056 16.92546584 27.95031056 21.27329193 16.77018634  8.69565217\n  Yes  3.50291910 17.40339172 29.19099249 25.38226300 15.15151515  6.95023631\n     \n                6           7           8\n  No   3.88198758  1.24223602  0.31055901\n  Yes  2.02946900  0.30581040  0.08340284\n\n#left skewed normal distribution - try to add a line showing the distribution - create different one then overlap?\nggplotly(ggplot(RQ3Viz, aes(x = factor(total_tests), fill = factor(Insurance))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Number of ER Tests by Insurance Status\",\n    x = \"Total Tests/Procedures\",\n    y = \"Number of Patients\",\n    fill = \"Insurance\"\n  ) +\n  theme_minimal())\n\n\n\n\n\nMultiple Linear Regression\n\nlibrary (caret)\n\nset.seed(1)\ntrain_index3 &lt;- createDataPartition(MergedDataRQ3$total_tests, \n                                    p = 0.7, \n                                    list = FALSE)\n\n# Training and testing datasets\ntrain_data3 &lt;- MergedDataRQ3[train_index3, ]\ntest_data3 &lt;- MergedDataRQ3[-train_index3, ]\n\n#traing on train data\nfit3 &lt;- lm(total_tests ~ factor(Insurance) + factor(SEX) + factor(POVCAT23),\n           data = train_data3)\n#Test on test\npred_lm3 = predict(fit3, newdata = test_data3)\n\nsummary(fit3)\n\n\nCall:\nlm(formula = total_tests ~ factor(Insurance) + factor(SEX) + \n    factor(POVCAT23), data = train_data3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9708 -0.8006  0.0292  1.0552  5.2626 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         2.73161    0.08486  32.188  &lt; 2e-16 ***\nfactor(Insurance)1 -0.17027    0.07134  -2.387 0.017067 *  \nfactor(SEX)1       -0.02602    0.05236  -0.497 0.619282    \nfactor(POVCAT23)2   0.11644    0.11075   1.051 0.293184    \nfactor(POVCAT23)3   0.02835    0.08245   0.344 0.731004    \nfactor(POVCAT23)4   0.00577    0.07258   0.079 0.936645    \nfactor(POVCAT23)5   0.23923    0.07195   3.325 0.000896 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.386 on 2963 degrees of freedom\nMultiple R-squared:  0.007598,  Adjusted R-squared:  0.005588 \nF-statistic: 3.781 on 6 and 2963 DF,  p-value: 0.0009368\n\n#Performance on Test Data\nRMSE(pred_lm3, test_data3$total_tests) #1.37 RMSE\n\n[1] 1.373271\n\nmean(abs(test_data3$total_tests - pred_lm3)) #1.115986 MAE\n\n[1] 1.115986\n\ncor(test_data3$total_tests, pred_lm3)^2 #0.007887108 RSQLM\n\n[1] 0.007887108\n\nvar(test_data3$total_tests) #1.9 most people in the data has 1.9 tests done - mean with fewer high/lower; low variance\n\n[1] 1.902351\n\n#hm = lm(Insurance ~ SEX, data = MergedDataRQ3)\n#summary (hm) #Being female (SEX = 1) increases probability of being insured by ~6.6%, holding everything else constant.\n\nPoisson regression\n\nset.seed(1)\n\n#Poisson Model on Train Data\nmodel_pois &lt;- glm(total_tests ~ factor(Insurance) + factor(SEX) + factor(POVCAT23),\n                  family = poisson(link = \"log\"), data = train_data3)\n#making prediction on test data\nPoss_pred_lm3 = predict(model_pois, newdata = test_data3,type = \"response\")\n\nsummary(model_pois)\n\n\nCall:\nglm(formula = total_tests ~ factor(Insurance) + factor(SEX) + \n    factor(POVCAT23), family = poisson(link = \"log\"), data = train_data3)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)         1.003330   0.037225  26.953  &lt; 2e-16 ***\nfactor(Insurance)1 -0.062767   0.030934  -2.029  0.04245 *  \nfactor(SEX)1       -0.009803   0.023172  -0.423  0.67225    \nfactor(POVCAT23)2   0.044392   0.049095   0.904  0.36588    \nfactor(POVCAT23)3   0.010936   0.037021   0.295  0.76768    \nfactor(POVCAT23)4   0.002358   0.032623   0.072  0.94237    \nfactor(POVCAT23)5   0.088898   0.031737   2.801  0.00509 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2338.2  on 2969  degrees of freedom\nResidual deviance: 2322.0  on 2963  degrees of freedom\nAIC: 10379\n\nNumber of Fisher Scoring iterations: 4\n\nRMSE(test_data3$total_tests, Poss_pred_lm3) #1.373308 RMSE\n\n[1] 1.373308\n\nmean(abs(test_data3$total_tests - Poss_pred_lm3)) #1.116015 MAE\n\n[1] 1.116015\n\ncor(test_data3$total_tests, Poss_pred_lm3)^2 #0.007838005 RSQLM\n\n[1] 0.007833137\n\n\nRandom Forest Regression\n\nlibrary(randomForest)\n\ntrain_data3 &lt;- MergedDataRQ3[train_index3, ]\ntest_data3 &lt;- MergedDataRQ3[-train_index3, ]\n\nrf.RQ3=randomForest(total_tests~.,data=train_data3, ntree = 500, importance = TRUE)\n\n#REGRESSION ANALYSIS FOR CONTINUOUS VARIABLE\n# Make predictions on the test set\npredictionsRQ3 = predict(rf.RQ3, newdata = test_data3)\n\nvarImpPlot(rf.RQ3)\n\n\n\n\n\n\n\nrf.RQ3\n\n\nCall:\n randomForest(formula = total_tests ~ ., data = train_data3, ntree = 500,      importance = TRUE) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 1\n\n          Mean of squared residuals: 1.922564\n                    % Var explained: 0.42\n\nplot(rf.RQ3)\n\n\n\n\n\n\n\nimportance(rf.RQ3)\n\n            %IncMSE IncNodePurity\nInsurance  8.256505     12.065347\nSEX        4.307670      7.157186\nPOVCAT23  18.839742     31.904179\n\nsummary (rf.RQ3)\n\n                Length Class  Mode     \ncall               5   -none- call     \ntype               1   -none- character\npredicted       2970   -none- numeric  \nmse              500   -none- numeric  \nrsq              500   -none- numeric  \noob.times       2970   -none- numeric  \nimportance         6   -none- numeric  \nimportanceSD       3   -none- numeric  \nlocalImportance    0   -none- NULL     \nproximity          0   -none- NULL     \nntree              1   -none- numeric  \nmtry               1   -none- numeric  \nforest            11   -none- list     \ncoefs              0   -none- NULL     \ny               2970   -none- numeric  \ntest               0   -none- NULL     \ninbag              0   -none- NULL     \nterms              3   terms  call     \n\n# Evaluate the model performance on test\n# Regression metrics\nsqrt(mean((test_data3$total_tests - predictionsRQ3)^2)) #RMSE 1.371164\n\n[1] 1.372646\n\nmean(abs(test_data3$total_tests - predictionsRQ3)) #MAE: 1.116\n\n[1] 1.117072\n\ncor(test_data3$total_tests , predictionsRQ3)^2 #RSQLM: 0.01054665\n\n[1] 0.0104738"
  },
  {
    "objectID": "HomePage.html",
    "href": "HomePage.html",
    "title": "Predictors of ER Admissions, Costs, and Test Utilization",
    "section": "",
    "text": "Welcome to the project website for the STAT 515 Final Project. This site summarizes the full analysis of emergency room (ER) utilization using the 2023 Medical Expenditure Panel Survey (MEPS) dataset.\n\n\nThis project investigates emergency room visits in the United States and examines:\n\nPredictors of inpatient admission after an ER visit.\nWhich ER characteristics lead to the highest total expenditures.\nWhether insurance status impacts the number of tests or procedures a patient receives, and how socioeconomic factors contribute.\n\nThe dataset includes 4,241 ER visits with information about: - Diagnostic tests (MRI/CT, X-ray, ultrasound, etc.) - Procedures (surgery, prescriptions) - Costs (facility, doctor, insurance payments, out-of-pocket) - Insurance coverage - Demographics (sex, poverty category)\nThis site contains the full project analysis, tables, models, visualizations, and interpretations.\n\n\n\nUse the sidebar to navigate between sections:\n\nHome — Project introduction\nDataset Overview & Preprocessing — Description of MEPS ER dataset\nResearch Question 1 — Predicting inpatient admission\nResearch Question 2 — Predicting total ER expenditures\nResearch Question 3 — Insurance status and number of tests\nConclusion — Summary of findings"
  },
  {
    "objectID": "HomePage.html#project-overview",
    "href": "HomePage.html#project-overview",
    "title": "Predictors of ER Admissions, Costs, and Test Utilization",
    "section": "",
    "text": "This project investigates emergency room visits in the United States and examines:\n\nPredictors of inpatient admission after an ER visit.\nWhich ER characteristics lead to the highest total expenditures.\nWhether insurance status impacts the number of tests or procedures a patient receives, and how socioeconomic factors contribute.\n\nThe dataset includes 4,241 ER visits with information about: - Diagnostic tests (MRI/CT, X-ray, ultrasound, etc.) - Procedures (surgery, prescriptions) - Costs (facility, doctor, insurance payments, out-of-pocket) - Insurance coverage - Demographics (sex, poverty category)\nThis site contains the full project analysis, tables, models, visualizations, and interpretations."
  },
  {
    "objectID": "HomePage.html#navigation",
    "href": "HomePage.html#navigation",
    "title": "Predictors of ER Admissions, Costs, and Test Utilization",
    "section": "",
    "text": "Use the sidebar to navigate between sections:\n\nHome — Project introduction\nDataset Overview & Preprocessing — Description of MEPS ER dataset\nResearch Question 1 — Predicting inpatient admission\nResearch Question 2 — Predicting total ER expenditures\nResearch Question 3 — Insurance status and number of tests\nConclusion — Summary of findings"
  },
  {
    "objectID": "RQ1-.html",
    "href": "RQ1-.html",
    "title": "Untitled",
    "section": "",
    "text": "Library Download\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.5.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n\n\n✔ broom        1.0.10     ✔ recipes      1.3.1 \n✔ dials        1.4.2      ✔ rsample      1.3.1 \n✔ dplyr        1.1.4      ✔ tailor       0.1.0 \n✔ ggplot2      4.0.1      ✔ tidyr        1.3.1 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ purrr        1.1.0      ✔ yardstick    1.3.2 \n\n\nWarning: package 'dials' was built under R version 4.5.2\n\n\nWarning: package 'dplyr' was built under R version 4.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\nWarning: package 'infer' was built under R version 4.5.2\n\n\nWarning: package 'modeldata' was built under R version 4.5.2\n\n\nWarning: package 'parsnip' was built under R version 4.5.2\n\n\nWarning: package 'recipes' was built under R version 4.5.2\n\n\nWarning: package 'rsample' was built under R version 4.5.2\n\n\nWarning: package 'tailor' was built under R version 4.5.2\n\n\nWarning: package 'tune' was built under R version 4.5.2\n\n\nWarning: package 'workflows' was built under R version 4.5.2\n\n\nWarning: package 'workflowsets' was built under R version 4.5.2\n\n\nWarning: package 'yardstick' was built under R version 4.5.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.5.2\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-10\n\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.5.2\n\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.5.2\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.5.2\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.5.2\n\n\nrandomForest 4.7-1.2\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:ranger':\n\n    importance\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nlibrary(tree)\n\nWarning: package 'tree' was built under R version 4.5.2\n\nlibrary(ISLR)\n\nWarning: package 'ISLR' was built under R version 4.5.2\n\nlibrary(dplyr)\nlibrary (plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:xgboost':\n\n    slice\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary (car)\n\nWarning: package 'car' was built under R version 4.5.2\n\n\nLoading required package: carData\n\n\nWarning: package 'carData' was built under R version 4.5.2\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nResearch Questions: 2. Which type of ER visits are the costliest for total ER expenditures? Types of tests / diagnostics? *note: Total ER expenditure is different than out of pocket\n\nOGData= read.csv(\"C:/Users/diane/downloads/h248e.csv\")\n\nLooking for Missing Values -1,-7,-8 shows missing / dont know vairbales completely remove varibles with these negative values - this dropped 317 observations\nRenaming Variables\n\nOGData_clean &lt;- OGData %&gt;%\n  # ── Keep only the variables we actually use across all 3 RQs ──\ndplyr:: select(\n    # Person-level ID and survey weight\n    person_id   = DUPERSID,\n    weight      = PERWT23F,\n    \n    # ── RQ1: Predict hospital admission ──\n    admitted    = ERHEVIDX,        # will recode below\n    \n    # Tests & diagnostics performed in ER (all yes/no → 0/1)\n    mri_ct      = MRI_M18,\n    surgery     = SURGPROC,\n    xray        = XRAYS_M18,\n    lab_tests   = LABTEST_M18,\n    ekg         = EKG_M18,\n    ultrasound  = SONOGRAM_M18,\n    mammogram   = MAMMOG_M18,\n    vaccination = RCVVAC_M18,\n    rx_given    = MEDPRESC,\n    related_condition = VSTRELCN,\n    \n    # ── RQ2: Total ER cost drivers ──\n    total_cost  = ERXP23X,         # total expenditure (facility + doctor)\n    \n    # ── RQ3: Out-of-pocket by insurance ──\n    oop_facility = ERFSF23X,       # self/family OOP facility\n    oop_doctor   = ERDSF23X,       # self/family OOP doctor\n    \n    private_fac  = ERFPV23X,\n    private_doc  = ERDPV23X,\n    medicaid_fac = ERFMD23X,\n    medicaid_doc = ERDMD23X,\n    medicare_fac = ERFMR23X,\n    medicare_doc = ERDMR23X\n  )\n\nAdding in Insurance Information\n\n#Cleaning Data to find Insurance v No Insurance\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(Insurance = case_when(\n    (private_fac &gt; 0  |  private_doc &gt; 0 | medicaid_fac &gt; 0 | medicaid_doc &gt; 0 | medicare_fac &gt; 0 | medicare_doc &gt; 0) ~ \"1\",\n    TRUE ~ \"0\"\n  ))\n\nOGData_clean$Insurance &lt;- as.numeric(OGData_clean$Insurance)\n\nCleaning up binary data Clean More Data - Deal with 95 & 1&2 to 0,1 remove -8 dont know variables 1 is yes 2 is no - changing to 0,1 - no - 0 yes 1\n\nyesno_vars &lt;- c(\n  \"mri_ct\", \"surgery\", \"xray\", \"lab_tests\", \"ekg\",\n  \"ultrasound\", \"mammogram\", \"vaccination\", \"rx_given\",\n  \"related_condition\")\n\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(across(all_of(yesno_vars), ~ ifelse(. == 1, 1, 0))) #keeps all the 1's and replaces the rest with 0\n\n#cleaning admitted inpatient for RQ1\nOGData_clean$admitted &lt;- ifelse(OGData_clean$admitted == \"-1\", 0, 1) #-1 not admitted - changing to 0;; recoding 1 to be admitted\ntable(OGData_clean$admitted) #not admitted 3345; admitted:896\n\n\n   0    1 \n3345  896 \n\n\nData Visualization for RQ1 - Skewed Data\n\n#creating new dataset to recode Admitted ad MRI CT to Yes / no\nRQ1Viz &lt;- OGData_clean %&gt;%\nmutate(admitted = factor(admitted, levels = c(0,1), labels = c(\"No\",\"Yes\")),\n        mri_ct = factor(mri_ct, levels = c(0,1), labels = c(\"No\",\"Yes\")))\n\n\nggplotly (ggplot(RQ1Viz, aes(x = factor(admitted), fill = factor(admitted))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Count of ER Visits by In Patient Admission Status\",\n    x = \"In Patient Admitted\",\n    y = \"Count\",\n    fill = \"Admitted\"\n  ) +\n  theme_minimal())\n\n\n\n\nggplotly(ggplot(RQ1Viz, aes(x = factor(admitted), fill = factor(mri_ct))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Hospital Admission by Whether MRI CT Was Performed\",\n    x = \"In Patient Admitted\",\n    y = \"Count\",\n    fill = \"MRI CT\"\n  ) +\n  geom_bar(position = \"stack\")+\n  theme_minimal())\n\n\n\n\nggplotly (ggplot(OGData_clean, aes(x = factor(admitted), fill = factor(surgery))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Hospital Admission by Whether Surgery Was Performed\",\n    x = \"Admitted (0 = No, 1 = Yes)\",\n    y = \"Count\",\n    fill = \"Surgery (0 = No, 1 = Yes)\"\n  ) +\n  geom_bar(position = \"stack\")+\n  theme_minimal())\n\n\n\n\n\nRQ 1 1. What predictors can help determine whether an ER visit results in an inpatient admission? Explore a number of predictors such as type of tests, diagnostics, and reason for visit\nhe confusion matrix, and sensitivity/recall for the “admitted” class (how many admitted patients your model correctly identifies).\nADD VARIABLE SELECTION METHOD BEFORE THIS****\n\nRQ1Data &lt;- OGData_clean %&gt;%\n  dplyr:: select(admitted,        \n    mri_ct      ,\n    surgery,\n    xray ,\n    lab_tests ,\n    ekg    ,\n    ultrasound ,\n    mammogram ,\n    vaccination ,\n    rx_given ,\n    related_condition,\n    Insurance)\n\nTrain & Test\n\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.5.2\n\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\n\nThe following object is masked from 'package:rsample':\n\n    calibration\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(car)\n\n\nset.seed(1)\ntrain_index = createDataPartition(RQ1Data$admitted, p = 0.8, list = FALSE) #createdatapartition ensures that admitted / not admitted are acurately represented in both train and test set*\ntrain_data = RQ1Data[train_index, ]\ntest_data = RQ1Data[-train_index, ]\n\nLogistic Regression\n\nglm_model &lt;- glm(admitted ~ ., data = RQ1Data, family = \"binomial\")\nvif(glm_model) #no multicolinerarity\n\n           mri_ct           surgery              xray         lab_tests \n         1.060226          1.036254          1.058423          1.150643 \n              ekg        ultrasound         mammogram       vaccination \n         1.161988          1.026398          1.006616          1.013955 \n         rx_given related_condition         Insurance \n         1.032644          1.012979          1.059200 \n\n#Train Data to predict admitted with Logistic Regression\nglm.admitted=glm(admitted~.,data=train_data,family=\"binomial\") #the . after ~ shows all variables\nsummary (glm.admitted)\n\n\nCall:\nglm(formula = admitted ~ ., family = \"binomial\", data = train_data)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -1.09992    0.19147  -5.744 9.22e-09 ***\nmri_ct              0.42790    0.10906   3.924 8.72e-05 ***\nsurgery             0.89785    0.18537   4.844 1.28e-06 ***\nxray               -0.03592    0.10341  -0.347    0.728    \nlab_tests           0.82450    0.10913   7.555 4.19e-14 ***\nekg                 0.62813    0.11301   5.558 2.72e-08 ***\nultrasound          0.54345    0.13630   3.987 6.69e-05 ***\nmammogram         -13.87172  238.18570  -0.058    0.954    \nvaccination        -0.18130    0.48603  -0.373    0.709    \nrx_given           -1.30270    0.13127  -9.924  &lt; 2e-16 ***\nrelated_condition   0.96239    0.17494   5.501 3.77e-08 ***\nInsurance          -2.13319    0.11567 -18.442  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3517.9  on 3392  degrees of freedom\nResidual deviance: 2758.8  on 3381  degrees of freedom\nAIC: 2782.8\n\nNumber of Fisher Scoring iterations: 13\n\n# Make predictions on the test set\npredictionsLR = predict(glm.admitted, newdata = test_data, type = \"response\")\n\n# Convert to class labels\nLR_pred &lt;- factor(ifelse(predictionsLR &gt; 0.5, 1, 0), levels = c(0, 1))\nLR_truth &lt;- factor(test_data$admitted, levels = c(0, 1))\n\n# Confusion matrix\nLR_cm &lt;- confusionMatrix(LR_pred, LR_truth) #81.9% accuracy\nLR_cm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 647 124\n         1  29  48\n                                         \n               Accuracy : 0.8196         \n                 95% CI : (0.792, 0.8449)\n    No Information Rate : 0.7972         \n    P-Value [Acc &gt; NIR] : 0.05553        \n                                         \n                  Kappa : 0.2974         \n                                         \n Mcnemar's Test P-Value : 2.974e-14      \n                                         \n            Sensitivity : 0.9571         \n            Specificity : 0.2791         \n         Pos Pred Value : 0.8392         \n         Neg Pred Value : 0.6234         \n             Prevalence : 0.7972         \n         Detection Rate : 0.7630         \n   Detection Prevalence : 0.9092         \n      Balanced Accuracy : 0.6181         \n                                         \n       'Positive' Class : 0              \n                                         \n\n#MSE\nmean((predictionsLR - test_data$admitted)^2) # 0.129\n\n[1] 0.1289928\n\n\nRandom Forest RQ1 - Classification Handles skewed data better\n\nlibrary(randomForest)\nlibrary(caret)\n\n# Train a Random Forest model to predict admitted\nrf_model = randomForest(as.factor(admitted) ~ ., data = train_data, ntree = 500)\nvarImpPlot(rf_model)\n\n\n\n\n\n\n\nrf_model\n\n\nCall:\n randomForest(formula = as.factor(admitted) ~ ., data = train_data,      ntree = 500) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n        OOB estimate of  error rate: 18.16%\nConfusion matrix:\n     0   1 class.error\n0 2585  84  0.03147246\n1  532 192  0.73480663\n\n(plot(rf_model))\n\n\n\n\n\n\n\n\n             OOB          0         1\n  [1,] 0.1835906 0.05648536 0.6254545\n  [2,] 0.1907371 0.05690537 0.6621622\n  [3,] 0.1786423 0.05005056 0.6487985\n  [4,] 0.1818823 0.04993252 0.6596091\n  [5,] 0.1817882 0.05296343 0.6518405\n  [6,] 0.1787180 0.05060241 0.6499261\n  [7,] 0.1840321 0.05492350 0.6575540\n  [8,] 0.1801148 0.05184332 0.6539007\n  [9,] 0.1821996 0.05074399 0.6634078\n [10,] 0.1817640 0.05273141 0.6541667\n [11,] 0.1827893 0.05134013 0.6657420\n [12,] 0.1818720 0.04975499 0.6666667\n [13,] 0.1794796 0.04701015 0.6666667\n [14,] 0.1806909 0.04656403 0.6740331\n [15,] 0.1802892 0.04615385 0.6740331\n [16,] 0.1798349 0.04572714 0.6740331\n [17,] 0.1794872 0.04383664 0.6795580\n [18,] 0.1788977 0.04308730 0.6795580\n [19,] 0.1791925 0.04271263 0.6823204\n [20,] 0.1786030 0.04383664 0.6754144\n [21,] 0.1803714 0.04496066 0.6795580\n [22,] 0.1783083 0.04308730 0.6767956\n [23,] 0.1788977 0.04046459 0.6892265\n [24,] 0.1806661 0.04121394 0.6947514\n [25,] 0.1786030 0.03821656 0.6961326\n [26,] 0.1806661 0.03671787 0.7113260\n [27,] 0.1791925 0.03709254 0.7030387\n [28,] 0.1771294 0.03484451 0.7016575\n [29,] 0.1777188 0.03521918 0.7030387\n [30,] 0.1794872 0.03821656 0.7002762\n [31,] 0.1780136 0.03671787 0.6988950\n [32,] 0.1800766 0.03784189 0.7044199\n [33,] 0.1783083 0.03521918 0.7058011\n [34,] 0.1797819 0.03596853 0.7099448\n [35,] 0.1786030 0.03484451 0.7085635\n [36,] 0.1788977 0.03409517 0.7127072\n [37,] 0.1791925 0.03446984 0.7127072\n [38,] 0.1788977 0.03372049 0.7140884\n [39,] 0.1786030 0.03297115 0.7154696\n [40,] 0.1791925 0.03409517 0.7140884\n [41,] 0.1791925 0.03372049 0.7154696\n [42,] 0.1800766 0.03372049 0.7196133\n [43,] 0.1803714 0.03259648 0.7251381\n [44,] 0.1809608 0.03222181 0.7292818\n [45,] 0.1818450 0.03297115 0.7306630\n [46,] 0.1815503 0.03222181 0.7320442\n [47,] 0.1800766 0.03184713 0.7265193\n [48,] 0.1815503 0.03222181 0.7320442\n [49,] 0.1812555 0.03109779 0.7348066\n [50,] 0.1818450 0.03259648 0.7320442\n [51,] 0.1806661 0.03109779 0.7320442\n [52,] 0.1806661 0.02997377 0.7361878\n [53,] 0.1818450 0.03222181 0.7334254\n [54,] 0.1806661 0.03072312 0.7334254\n [55,] 0.1812555 0.03109779 0.7348066\n [56,] 0.1812555 0.03184713 0.7320442\n [57,] 0.1812555 0.03222181 0.7306630\n [58,] 0.1818450 0.03259648 0.7320442\n [59,] 0.1830239 0.03297115 0.7361878\n [60,] 0.1821397 0.03297115 0.7320442\n [61,] 0.1812555 0.03147246 0.7334254\n [62,] 0.1809608 0.03072312 0.7348066\n [63,] 0.1803714 0.03034845 0.7334254\n [64,] 0.1794872 0.02959910 0.7320442\n [65,] 0.1809608 0.03034845 0.7361878\n [66,] 0.1806661 0.03109779 0.7320442\n [67,] 0.1803714 0.02997377 0.7348066\n [68,] 0.1806661 0.03034845 0.7348066\n [69,] 0.1806661 0.03034845 0.7348066\n [70,] 0.1812555 0.03109779 0.7348066\n [71,] 0.1797819 0.02959910 0.7334254\n [72,] 0.1803714 0.02997377 0.7348066\n [73,] 0.1806661 0.03072312 0.7334254\n [74,] 0.1803714 0.03034845 0.7334254\n [75,] 0.1818450 0.03072312 0.7389503\n [76,] 0.1815503 0.03034845 0.7389503\n [77,] 0.1806661 0.03184713 0.7292818\n [78,] 0.1809608 0.03184713 0.7306630\n [79,] 0.1812555 0.03072312 0.7361878\n [80,] 0.1809608 0.03184713 0.7306630\n [81,] 0.1824344 0.03297115 0.7334254\n [82,] 0.1824344 0.03334582 0.7320442\n [83,] 0.1821397 0.03409517 0.7279006\n [84,] 0.1830239 0.03372049 0.7334254\n [85,] 0.1812555 0.03184713 0.7320442\n [86,] 0.1809608 0.03147246 0.7320442\n [87,] 0.1809608 0.03147246 0.7320442\n [88,] 0.1812555 0.03072312 0.7361878\n [89,] 0.1821397 0.03259648 0.7334254\n [90,] 0.1818450 0.03259648 0.7320442\n [91,] 0.1824344 0.03259648 0.7348066\n [92,] 0.1821397 0.03259648 0.7334254\n [93,] 0.1830239 0.03409517 0.7320442\n [94,] 0.1830239 0.03446984 0.7306630\n [95,] 0.1821397 0.03372049 0.7292818\n [96,] 0.1818450 0.03484451 0.7237569\n [97,] 0.1824344 0.03559386 0.7237569\n [98,] 0.1818450 0.03409517 0.7265193\n [99,] 0.1818450 0.03484451 0.7237569\n[100,] 0.1821397 0.03372049 0.7292818\n[101,] 0.1824344 0.03446984 0.7279006\n[102,] 0.1815503 0.03372049 0.7265193\n[103,] 0.1803714 0.03184713 0.7279006\n[104,] 0.1815503 0.03334582 0.7279006\n[105,] 0.1818450 0.03334582 0.7292818\n[106,] 0.1812555 0.03222181 0.7306630\n[107,] 0.1815503 0.03259648 0.7306630\n[108,] 0.1821397 0.03259648 0.7334254\n[109,] 0.1824344 0.03334582 0.7320442\n[110,] 0.1818450 0.03222181 0.7334254\n[111,] 0.1821397 0.03297115 0.7320442\n[112,] 0.1824344 0.03222181 0.7361878\n[113,] 0.1821397 0.03222181 0.7348066\n[114,] 0.1821397 0.03184713 0.7361878\n[115,] 0.1818450 0.03184713 0.7348066\n[116,] 0.1818450 0.03184713 0.7348066\n[117,] 0.1818450 0.03259648 0.7320442\n[118,] 0.1827291 0.03334582 0.7334254\n[119,] 0.1818450 0.03259648 0.7320442\n[120,] 0.1827291 0.03334582 0.7334254\n[121,] 0.1830239 0.03372049 0.7334254\n[122,] 0.1821397 0.03334582 0.7306630\n[123,] 0.1821397 0.03334582 0.7306630\n[124,] 0.1821397 0.03259648 0.7334254\n[125,] 0.1821397 0.03184713 0.7361878\n[126,] 0.1809608 0.03147246 0.7320442\n[127,] 0.1818450 0.03147246 0.7361878\n[128,] 0.1824344 0.03222181 0.7361878\n[129,] 0.1827291 0.03259648 0.7361878\n[130,] 0.1824344 0.03259648 0.7348066\n[131,] 0.1818450 0.03222181 0.7334254\n[132,] 0.1827291 0.03297115 0.7348066\n[133,] 0.1830239 0.03409517 0.7320442\n[134,] 0.1842028 0.03446984 0.7361878\n[135,] 0.1842028 0.03559386 0.7320442\n[136,] 0.1830239 0.03484451 0.7292818\n[137,] 0.1836133 0.03521918 0.7306630\n[138,] 0.1830239 0.03446984 0.7306630\n[139,] 0.1836133 0.03484451 0.7320442\n[140,] 0.1827291 0.03409517 0.7306630\n[141,] 0.1824344 0.03372049 0.7306630\n[142,] 0.1824344 0.03297115 0.7334254\n[143,] 0.1821397 0.03297115 0.7320442\n[144,] 0.1821397 0.03297115 0.7320442\n[145,] 0.1824344 0.03297115 0.7334254\n[146,] 0.1824344 0.03259648 0.7348066\n[147,] 0.1821397 0.03259648 0.7334254\n[148,] 0.1827291 0.03334582 0.7334254\n[149,] 0.1830239 0.03372049 0.7334254\n[150,] 0.1821397 0.03259648 0.7334254\n[151,] 0.1830239 0.03334582 0.7348066\n[152,] 0.1824344 0.03259648 0.7348066\n[153,] 0.1824344 0.03259648 0.7348066\n[154,] 0.1827291 0.03334582 0.7334254\n[155,] 0.1815503 0.03297115 0.7292818\n[156,] 0.1821397 0.03372049 0.7292818\n[157,] 0.1827291 0.03409517 0.7306630\n[158,] 0.1815503 0.03334582 0.7279006\n[159,] 0.1821397 0.03297115 0.7320442\n[160,] 0.1815503 0.03259648 0.7306630\n[161,] 0.1818450 0.03297115 0.7306630\n[162,] 0.1815503 0.03259648 0.7306630\n[163,] 0.1818450 0.03297115 0.7306630\n[164,] 0.1821397 0.03222181 0.7348066\n[165,] 0.1821397 0.03222181 0.7348066\n[166,] 0.1809608 0.03072312 0.7348066\n[167,] 0.1815503 0.03184713 0.7334254\n[168,] 0.1815503 0.03259648 0.7306630\n[169,] 0.1818450 0.03259648 0.7320442\n[170,] 0.1818450 0.03297115 0.7306630\n[171,] 0.1818450 0.03222181 0.7334254\n[172,] 0.1812555 0.03184713 0.7320442\n[173,] 0.1806661 0.03109779 0.7320442\n[174,] 0.1815503 0.03184713 0.7334254\n[175,] 0.1806661 0.03072312 0.7334254\n[176,] 0.1812555 0.03147246 0.7334254\n[177,] 0.1803714 0.02997377 0.7348066\n[178,] 0.1806661 0.03034845 0.7348066\n[179,] 0.1806661 0.03109779 0.7320442\n[180,] 0.1803714 0.03109779 0.7306630\n[181,] 0.1800766 0.03034845 0.7320442\n[182,] 0.1806661 0.03034845 0.7348066\n[183,] 0.1803714 0.03034845 0.7334254\n[184,] 0.1815503 0.03034845 0.7389503\n[185,] 0.1803714 0.02922443 0.7375691\n[186,] 0.1800766 0.02959910 0.7348066\n[187,] 0.1809608 0.02997377 0.7375691\n[188,] 0.1803714 0.02959910 0.7361878\n[189,] 0.1803714 0.02959910 0.7361878\n[190,] 0.1800766 0.02922443 0.7361878\n[191,] 0.1797819 0.02884976 0.7361878\n[192,] 0.1803714 0.02959910 0.7361878\n[193,] 0.1803714 0.02997377 0.7348066\n[194,] 0.1797819 0.02959910 0.7334254\n[195,] 0.1800766 0.02922443 0.7361878\n[196,] 0.1803714 0.02922443 0.7375691\n[197,] 0.1812555 0.02922443 0.7417127\n[198,] 0.1806661 0.02922443 0.7389503\n[199,] 0.1806661 0.02922443 0.7389503\n[200,] 0.1803714 0.02884976 0.7389503\n[201,] 0.1800766 0.02847508 0.7389503\n[202,] 0.1803714 0.02847508 0.7403315\n[203,] 0.1803714 0.02884976 0.7389503\n[204,] 0.1800766 0.02847508 0.7389503\n[205,] 0.1800766 0.02847508 0.7389503\n[206,] 0.1797819 0.02772574 0.7403315\n[207,] 0.1797819 0.02772574 0.7403315\n[208,] 0.1800766 0.02735107 0.7430939\n[209,] 0.1797819 0.02735107 0.7417127\n[210,] 0.1794872 0.02735107 0.7403315\n[211,] 0.1797819 0.02735107 0.7417127\n[212,] 0.1800766 0.02772574 0.7417127\n[213,] 0.1809608 0.02847508 0.7430939\n[214,] 0.1812555 0.02922443 0.7417127\n[215,] 0.1815503 0.02959910 0.7417127\n[216,] 0.1809608 0.02884976 0.7417127\n[217,] 0.1803714 0.02959910 0.7361878\n[218,] 0.1800766 0.02884976 0.7375691\n[219,] 0.1800766 0.02884976 0.7375691\n[220,] 0.1803714 0.02959910 0.7361878\n[221,] 0.1797819 0.02847508 0.7375691\n[222,] 0.1800766 0.02884976 0.7375691\n[223,] 0.1800766 0.02884976 0.7375691\n[224,] 0.1803714 0.02922443 0.7375691\n[225,] 0.1806661 0.02959910 0.7375691\n[226,] 0.1806661 0.02959910 0.7375691\n[227,] 0.1809608 0.02997377 0.7375691\n[228,] 0.1800766 0.02884976 0.7375691\n[229,] 0.1803714 0.02959910 0.7361878\n[230,] 0.1815503 0.02997377 0.7403315\n[231,] 0.1809608 0.02922443 0.7403315\n[232,] 0.1812555 0.02959910 0.7403315\n[233,] 0.1812555 0.02959910 0.7403315\n[234,] 0.1812555 0.02997377 0.7389503\n[235,] 0.1815503 0.03034845 0.7389503\n[236,] 0.1803714 0.02959910 0.7361878\n[237,] 0.1809608 0.02997377 0.7375691\n[238,] 0.1812555 0.02997377 0.7389503\n[239,] 0.1809608 0.03034845 0.7361878\n[240,] 0.1809608 0.03072312 0.7348066\n[241,] 0.1815503 0.03109779 0.7361878\n[242,] 0.1806661 0.03072312 0.7334254\n[243,] 0.1815503 0.03072312 0.7375691\n[244,] 0.1800766 0.02922443 0.7361878\n[245,] 0.1806661 0.02997377 0.7361878\n[246,] 0.1815503 0.03072312 0.7375691\n[247,] 0.1806661 0.02997377 0.7361878\n[248,] 0.1806661 0.02959910 0.7375691\n[249,] 0.1806661 0.02959910 0.7375691\n[250,] 0.1812555 0.02997377 0.7389503\n[251,] 0.1806661 0.02922443 0.7389503\n[252,] 0.1815503 0.02997377 0.7403315\n[253,] 0.1815503 0.03034845 0.7389503\n[254,] 0.1812555 0.02959910 0.7403315\n[255,] 0.1812555 0.02959910 0.7403315\n[256,] 0.1809608 0.02959910 0.7389503\n[257,] 0.1815503 0.02997377 0.7403315\n[258,] 0.1815503 0.02997377 0.7403315\n[259,] 0.1809608 0.02959910 0.7389503\n[260,] 0.1803714 0.02922443 0.7375691\n[261,] 0.1806661 0.02922443 0.7389503\n[262,] 0.1812555 0.02959910 0.7403315\n[263,] 0.1806661 0.02922443 0.7389503\n[264,] 0.1797819 0.02810041 0.7389503\n[265,] 0.1803714 0.02884976 0.7389503\n[266,] 0.1806661 0.02959910 0.7375691\n[267,] 0.1806661 0.02922443 0.7389503\n[268,] 0.1803714 0.02884976 0.7389503\n[269,] 0.1800766 0.02847508 0.7389503\n[270,] 0.1803714 0.02922443 0.7375691\n[271,] 0.1800766 0.02884976 0.7375691\n[272,] 0.1818450 0.02997377 0.7417127\n[273,] 0.1821397 0.02997377 0.7430939\n[274,] 0.1818450 0.02997377 0.7417127\n[275,] 0.1812555 0.02997377 0.7389503\n[276,] 0.1815503 0.02997377 0.7403315\n[277,] 0.1818450 0.02997377 0.7417127\n[278,] 0.1821397 0.03034845 0.7417127\n[279,] 0.1818450 0.03034845 0.7403315\n[280,] 0.1818450 0.02997377 0.7417127\n[281,] 0.1812555 0.02997377 0.7389503\n[282,] 0.1812555 0.02997377 0.7389503\n[283,] 0.1809608 0.03034845 0.7361878\n[284,] 0.1812555 0.03034845 0.7375691\n[285,] 0.1809608 0.03034845 0.7361878\n[286,] 0.1806661 0.03034845 0.7348066\n[287,] 0.1809608 0.03034845 0.7361878\n[288,] 0.1803714 0.02997377 0.7348066\n[289,] 0.1800766 0.02997377 0.7334254\n[290,] 0.1803714 0.02997377 0.7348066\n[291,] 0.1803714 0.03034845 0.7334254\n[292,] 0.1800766 0.03034845 0.7320442\n[293,] 0.1797819 0.03072312 0.7292818\n[294,] 0.1803714 0.02997377 0.7348066\n[295,] 0.1794872 0.02997377 0.7306630\n[296,] 0.1800766 0.03072312 0.7306630\n[297,] 0.1800766 0.03072312 0.7306630\n[298,] 0.1794872 0.03072312 0.7279006\n[299,] 0.1797819 0.03147246 0.7265193\n[300,] 0.1791925 0.03109779 0.7251381\n[301,] 0.1797819 0.03109779 0.7279006\n[302,] 0.1794872 0.03072312 0.7279006\n[303,] 0.1791925 0.03072312 0.7265193\n[304,] 0.1791925 0.03034845 0.7279006\n[305,] 0.1794872 0.03034845 0.7292818\n[306,] 0.1794872 0.03072312 0.7279006\n[307,] 0.1786030 0.02997377 0.7265193\n[308,] 0.1786030 0.03034845 0.7251381\n[309,] 0.1788977 0.03034845 0.7265193\n[310,] 0.1791925 0.03072312 0.7265193\n[311,] 0.1797819 0.03109779 0.7279006\n[312,] 0.1797819 0.03147246 0.7265193\n[313,] 0.1794872 0.03109779 0.7265193\n[314,] 0.1803714 0.03184713 0.7279006\n[315,] 0.1797819 0.03147246 0.7265193\n[316,] 0.1803714 0.03184713 0.7279006\n[317,] 0.1803714 0.03184713 0.7279006\n[318,] 0.1797819 0.03147246 0.7265193\n[319,] 0.1800766 0.03147246 0.7279006\n[320,] 0.1794872 0.03147246 0.7251381\n[321,] 0.1797819 0.03147246 0.7265193\n[322,] 0.1797819 0.03109779 0.7279006\n[323,] 0.1797819 0.03109779 0.7279006\n[324,] 0.1800766 0.03109779 0.7292818\n[325,] 0.1797819 0.03109779 0.7279006\n[326,] 0.1791925 0.03109779 0.7251381\n[327,] 0.1797819 0.03109779 0.7279006\n[328,] 0.1800766 0.03147246 0.7279006\n[329,] 0.1794872 0.03147246 0.7251381\n[330,] 0.1800766 0.03184713 0.7265193\n[331,] 0.1797819 0.03147246 0.7265193\n[332,] 0.1791925 0.03109779 0.7251381\n[333,] 0.1794872 0.03109779 0.7265193\n[334,] 0.1797819 0.03147246 0.7265193\n[335,] 0.1797819 0.03147246 0.7265193\n[336,] 0.1800766 0.03109779 0.7292818\n[337,] 0.1797819 0.03147246 0.7265193\n[338,] 0.1797819 0.03147246 0.7265193\n[339,] 0.1800766 0.03184713 0.7265193\n[340,] 0.1797819 0.03184713 0.7251381\n[341,] 0.1794872 0.03147246 0.7251381\n[342,] 0.1791925 0.03072312 0.7265193\n[343,] 0.1788977 0.03034845 0.7265193\n[344,] 0.1791925 0.03034845 0.7279006\n[345,] 0.1797819 0.03072312 0.7292818\n[346,] 0.1794872 0.03109779 0.7265193\n[347,] 0.1797819 0.03109779 0.7279006\n[348,] 0.1794872 0.03072312 0.7279006\n[349,] 0.1794872 0.03109779 0.7265193\n[350,] 0.1800766 0.03147246 0.7279006\n[351,] 0.1800766 0.03147246 0.7279006\n[352,] 0.1806661 0.03184713 0.7292818\n[353,] 0.1806661 0.03147246 0.7306630\n[354,] 0.1803714 0.03147246 0.7292818\n[355,] 0.1803714 0.03109779 0.7306630\n[356,] 0.1803714 0.03147246 0.7292818\n[357,] 0.1806661 0.03147246 0.7306630\n[358,] 0.1803714 0.03109779 0.7306630\n[359,] 0.1812555 0.03222181 0.7306630\n[360,] 0.1803714 0.03147246 0.7292818\n[361,] 0.1806661 0.03147246 0.7306630\n[362,] 0.1803714 0.03109779 0.7306630\n[363,] 0.1809608 0.03147246 0.7320442\n[364,] 0.1809608 0.03147246 0.7320442\n[365,] 0.1806661 0.03147246 0.7306630\n[366,] 0.1803714 0.03147246 0.7292818\n[367,] 0.1800766 0.03147246 0.7279006\n[368,] 0.1803714 0.03147246 0.7292818\n[369,] 0.1800766 0.03109779 0.7292818\n[370,] 0.1806661 0.03147246 0.7306630\n[371,] 0.1806661 0.03147246 0.7306630\n[372,] 0.1806661 0.03147246 0.7306630\n[373,] 0.1803714 0.03109779 0.7306630\n[374,] 0.1803714 0.03072312 0.7320442\n[375,] 0.1800766 0.03072312 0.7306630\n[376,] 0.1806661 0.03109779 0.7320442\n[377,] 0.1803714 0.03109779 0.7306630\n[378,] 0.1803714 0.03109779 0.7306630\n[379,] 0.1806661 0.03147246 0.7306630\n[380,] 0.1809608 0.03184713 0.7306630\n[381,] 0.1806661 0.03147246 0.7306630\n[382,] 0.1803714 0.03109779 0.7306630\n[383,] 0.1797819 0.03034845 0.7306630\n[384,] 0.1800766 0.03034845 0.7320442\n[385,] 0.1800766 0.03072312 0.7306630\n[386,] 0.1803714 0.03109779 0.7306630\n[387,] 0.1803714 0.03072312 0.7320442\n[388,] 0.1809608 0.03147246 0.7320442\n[389,] 0.1806661 0.03109779 0.7320442\n[390,] 0.1809608 0.03109779 0.7334254\n[391,] 0.1800766 0.03109779 0.7292818\n[392,] 0.1806661 0.03147246 0.7306630\n[393,] 0.1806661 0.03147246 0.7306630\n[394,] 0.1809608 0.03147246 0.7320442\n[395,] 0.1815503 0.03147246 0.7348066\n[396,] 0.1815503 0.03184713 0.7334254\n[397,] 0.1812555 0.03184713 0.7320442\n[398,] 0.1809608 0.03147246 0.7320442\n[399,] 0.1809608 0.03147246 0.7320442\n[400,] 0.1812555 0.03147246 0.7334254\n[401,] 0.1809608 0.03147246 0.7320442\n[402,] 0.1818450 0.03184713 0.7348066\n[403,] 0.1818450 0.03184713 0.7348066\n[404,] 0.1812555 0.03147246 0.7334254\n[405,] 0.1815503 0.03184713 0.7334254\n[406,] 0.1818450 0.03147246 0.7361878\n[407,] 0.1815503 0.03184713 0.7334254\n[408,] 0.1815503 0.03184713 0.7334254\n[409,] 0.1815503 0.03184713 0.7334254\n[410,] 0.1821397 0.03222181 0.7348066\n[411,] 0.1824344 0.03259648 0.7348066\n[412,] 0.1821397 0.03259648 0.7334254\n[413,] 0.1812555 0.03222181 0.7306630\n[414,] 0.1821397 0.03259648 0.7334254\n[415,] 0.1821397 0.03297115 0.7320442\n[416,] 0.1818450 0.03259648 0.7320442\n[417,] 0.1818450 0.03259648 0.7320442\n[418,] 0.1815503 0.03259648 0.7306630\n[419,] 0.1818450 0.03259648 0.7320442\n[420,] 0.1818450 0.03259648 0.7320442\n[421,] 0.1821397 0.03334582 0.7306630\n[422,] 0.1818450 0.03297115 0.7306630\n[423,] 0.1824344 0.03372049 0.7306630\n[424,] 0.1818450 0.03297115 0.7306630\n[425,] 0.1824344 0.03334582 0.7320442\n[426,] 0.1818450 0.03259648 0.7320442\n[427,] 0.1815503 0.03222181 0.7320442\n[428,] 0.1815503 0.03259648 0.7306630\n[429,] 0.1818450 0.03334582 0.7292818\n[430,] 0.1818450 0.03297115 0.7306630\n[431,] 0.1818450 0.03297115 0.7306630\n[432,] 0.1809608 0.03184713 0.7306630\n[433,] 0.1809608 0.03184713 0.7306630\n[434,] 0.1818450 0.03259648 0.7320442\n[435,] 0.1821397 0.03334582 0.7306630\n[436,] 0.1815503 0.03222181 0.7320442\n[437,] 0.1821397 0.03297115 0.7320442\n[438,] 0.1821397 0.03259648 0.7334254\n[439,] 0.1818450 0.03184713 0.7348066\n[440,] 0.1818450 0.03222181 0.7334254\n[441,] 0.1815503 0.03222181 0.7320442\n[442,] 0.1821397 0.03297115 0.7320442\n[443,] 0.1824344 0.03334582 0.7320442\n[444,] 0.1827291 0.03334582 0.7334254\n[445,] 0.1818450 0.03222181 0.7334254\n[446,] 0.1818450 0.03222181 0.7334254\n[447,] 0.1818450 0.03222181 0.7334254\n[448,] 0.1821397 0.03222181 0.7348066\n[449,] 0.1821397 0.03222181 0.7348066\n[450,] 0.1827291 0.03297115 0.7348066\n[451,] 0.1827291 0.03297115 0.7348066\n[452,] 0.1827291 0.03259648 0.7361878\n[453,] 0.1830239 0.03297115 0.7361878\n[454,] 0.1827291 0.03259648 0.7361878\n[455,] 0.1827291 0.03222181 0.7375691\n[456,] 0.1827291 0.03184713 0.7389503\n[457,] 0.1827291 0.03184713 0.7389503\n[458,] 0.1824344 0.03147246 0.7389503\n[459,] 0.1824344 0.03147246 0.7389503\n[460,] 0.1821397 0.03147246 0.7375691\n[461,] 0.1821397 0.03147246 0.7375691\n[462,] 0.1821397 0.03147246 0.7375691\n[463,] 0.1821397 0.03147246 0.7375691\n[464,] 0.1815503 0.03147246 0.7348066\n[465,] 0.1821397 0.03184713 0.7361878\n[466,] 0.1818450 0.03147246 0.7361878\n[467,] 0.1824344 0.03184713 0.7375691\n[468,] 0.1821397 0.03147246 0.7375691\n[469,] 0.1821397 0.03147246 0.7375691\n[470,] 0.1815503 0.03072312 0.7375691\n[471,] 0.1815503 0.03034845 0.7389503\n[472,] 0.1809608 0.02997377 0.7375691\n[473,] 0.1818450 0.03109779 0.7375691\n[474,] 0.1821397 0.03184713 0.7361878\n[475,] 0.1821397 0.03147246 0.7375691\n[476,] 0.1818450 0.03147246 0.7361878\n[477,] 0.1812555 0.03072312 0.7361878\n[478,] 0.1815503 0.03109779 0.7361878\n[479,] 0.1821397 0.03147246 0.7375691\n[480,] 0.1812555 0.03034845 0.7375691\n[481,] 0.1815503 0.03109779 0.7361878\n[482,] 0.1815503 0.03072312 0.7375691\n[483,] 0.1815503 0.03072312 0.7375691\n[484,] 0.1812555 0.03072312 0.7361878\n[485,] 0.1818450 0.03147246 0.7361878\n[486,] 0.1821397 0.03147246 0.7375691\n[487,] 0.1809608 0.03034845 0.7361878\n[488,] 0.1815503 0.03109779 0.7361878\n[489,] 0.1818450 0.03109779 0.7375691\n[490,] 0.1815503 0.03147246 0.7348066\n[491,] 0.1818450 0.03147246 0.7361878\n[492,] 0.1818450 0.03147246 0.7361878\n[493,] 0.1815503 0.03109779 0.7361878\n[494,] 0.1812555 0.03072312 0.7361878\n[495,] 0.1812555 0.03109779 0.7348066\n[496,] 0.1818450 0.03184713 0.7348066\n[497,] 0.1812555 0.03109779 0.7348066\n[498,] 0.1815503 0.03109779 0.7361878\n[499,] 0.1815503 0.03147246 0.7348066\n[500,] 0.1815503 0.03147246 0.7348066\n\nsummary (rf_model)\n\n                Length Class  Mode     \ncall               4   -none- call     \ntype               1   -none- character\npredicted       3393   factor numeric  \nerr.rate        1500   -none- numeric  \nconfusion          6   -none- numeric  \nvotes           6786   matrix numeric  \noob.times       3393   -none- numeric  \nclasses            2   -none- character\nimportance        11   -none- numeric  \nimportanceSD       0   -none- NULL     \nlocalImportance    0   -none- NULL     \nproximity          0   -none- NULL     \nntree              1   -none- numeric  \nmtry               1   -none- numeric  \nforest            14   -none- list     \ny               3393   factor numeric  \ntest               0   -none- NULL     \ninbag              0   -none- NULL     \nterms              3   terms  call     \n\n# Make predictions on the test set\npredictions = predict(rf_model, newdata = test_data)\n\n#model performance\n#rf_model$mse\n#which.min(mse) #362 trees used \n\nmean(predictions == test_data$admitted) #81.7\n\n[1] 0.817217\n\nconfusionMatrix(predictions, as.factor(test_data$admitted)) #confusion matrix\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 653 132\n         1  23  40\n                                          \n               Accuracy : 0.8172          \n                 95% CI : (0.7895, 0.8427)\n    No Information Rate : 0.7972          \n    P-Value [Acc &gt; NIR] : 0.07809         \n                                          \n                  Kappa : 0.2599          \n                                          \n Mcnemar's Test P-Value : &lt; 2e-16         \n                                          \n            Sensitivity : 0.9660          \n            Specificity : 0.2326          \n         Pos Pred Value : 0.8318          \n         Neg Pred Value : 0.6349          \n             Prevalence : 0.7972          \n         Detection Rate : 0.7700          \n   Detection Prevalence : 0.9257          \n      Balanced Accuracy : 0.5993          \n                                          \n       'Positive' Class : 0"
  },
  {
    "objectID": "RQ2-.html",
    "href": "RQ2-.html",
    "title": "RQ2",
    "section": "",
    "text": "Library Download\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.5.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n\n\n✔ broom        1.0.10     ✔ recipes      1.3.1 \n✔ dials        1.4.2      ✔ rsample      1.3.1 \n✔ dplyr        1.1.4      ✔ tailor       0.1.0 \n✔ ggplot2      4.0.1      ✔ tidyr        1.3.1 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ purrr        1.1.0      ✔ yardstick    1.3.2 \n\n\nWarning: package 'dials' was built under R version 4.5.2\n\n\nWarning: package 'dplyr' was built under R version 4.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\nWarning: package 'infer' was built under R version 4.5.2\n\n\nWarning: package 'modeldata' was built under R version 4.5.2\n\n\nWarning: package 'parsnip' was built under R version 4.5.2\n\n\nWarning: package 'recipes' was built under R version 4.5.2\n\n\nWarning: package 'rsample' was built under R version 4.5.2\n\n\nWarning: package 'tailor' was built under R version 4.5.2\n\n\nWarning: package 'tune' was built under R version 4.5.2\n\n\nWarning: package 'workflows' was built under R version 4.5.2\n\n\nWarning: package 'workflowsets' was built under R version 4.5.2\n\n\nWarning: package 'yardstick' was built under R version 4.5.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.5.2\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-10\n\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.5.2\n\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.5.2\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.5.2\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.5.2\n\n\nrandomForest 4.7-1.2\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:ranger':\n\n    importance\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nlibrary(tree)\n\nWarning: package 'tree' was built under R version 4.5.2\n\nlibrary(ISLR)\n\nWarning: package 'ISLR' was built under R version 4.5.2\n\nlibrary(dplyr)\nlibrary (plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:xgboost':\n\n    slice\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(caret)\n\nWarning: package 'caret' was built under R version 4.5.2\n\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\n\nThe following object is masked from 'package:rsample':\n\n    calibration\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\n\nResearch Questions: 2. Which type of ER visits are the costliest for total ER expenditures? Types of tests / diagnostics? *note: Total ER expenditure is different than out of pocket\n\nOGData= read.csv(\"C:/Users/diane/downloads/h248e.csv\")\n\nLooking for Missing Values -1,-7,-8 shows missing / dont know vairbales completely remove varibles with these negative values - this dropped 317 observations\n\ntable(is.na(OGData)) #no missing data\n\n\n FALSE \n224773 \n\nstr (OGData) #shows variables are all integers and numeric\n\n'data.frame':   4241 obs. of  53 variables:\n $ DUID        : int  2790032 2790037 2790043 2790043 2790043 2790045 2790046 2790046 2790050 2790050 ...\n $ PID         : int  106 101 101 101 103 101 103 103 101 102 ...\n $ DUPERSID    : num  2.79e+09 2.79e+09 2.79e+09 2.79e+09 2.79e+09 ...\n $ EVNTIDX     : num  2.79e+15 2.79e+15 2.79e+15 2.79e+15 2.79e+15 ...\n $ EVENTRN     : int  3 3 4 5 3 3 3 3 5 3 ...\n $ ERHEVIDX    : num  -1 -1 -1 -1 -1 ...\n $ FFEEIDX     : int  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...\n $ PANEL       : int  27 27 27 27 27 27 27 27 27 27 ...\n $ MPCDATA     : int  1 2 1 2 1 1 2 1 2 1 ...\n $ ERDATEYR    : int  2023 2023 2023 2023 2023 2023 2023 2023 2023 2023 ...\n $ ERDATEMM    : int  1 1 6 8 1 4 2 2 12 1 ...\n $ VSTCTGRY    : int  1 1 1 2 1 2 2 2 1 1 ...\n $ VSTRELCN    : int  1 1 1 1 1 1 1 1 1 1 ...\n $ LABTEST_M18 : int  1 2 1 1 1 1 1 1 1 1 ...\n $ SONOGRAM_M18: int  2 2 2 2 2 2 2 2 2 2 ...\n $ XRAYS_M18   : int  2 2 2 2 1 1 2 2 2 2 ...\n $ MAMMOG_M18  : int  2 2 2 2 2 2 2 2 2 2 ...\n $ MRI_M18     : int  2 1 2 1 2 2 1 2 1 1 ...\n $ EKG_M18     : int  2 1 2 1 2 2 2 2 2 2 ...\n $ RCVVAC_M18  : int  2 2 2 2 2 2 2 2 2 2 ...\n $ SURGPROC    : int  2 2 2 2 2 2 2 2 2 2 ...\n $ MEDPRESC    : int  1 2 2 1 2 2 2 2 2 2 ...\n $ FFERTYPE    : int  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 ...\n $ ERXP23X     : num  449 633 1009 636 478 ...\n $ ERTC23X     : num  8717 4664 5891 3888 2542 ...\n $ ERFSF23X    : num  0 0 0 0 0 ...\n $ ERFMR23X    : num  0 196 574 500 0 ...\n $ ERFMD23X    : num  257 0 0 0 0 ...\n $ ERFPV23X    : num  0 50.1 146.5 127.6 0 ...\n $ ERFVA23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERFTR23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERFOF23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERFSL23X    : num  0 0 0 0 478 ...\n $ ERFWC23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERFOT23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERFXP23X    : num  257 247 721 628 478 ...\n $ ERFTC23X    : num  6895 3303 4534 3852 2297 ...\n $ ERDSF23X    : num  101 0 0 0 0 ...\n $ ERDMR23X    : num  0 385.3 286.5 8.6 0 ...\n $ ERDMD23X    : num  91.9 0 0 0 0 ...\n $ ERDPV23X    : num  0 1.44 2.03 0 0 ...\n $ ERDVA23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERDTR23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERDOF23X    : int  0 0 0 0 0 0 0 0 0 0 ...\n $ ERDSL23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERDWC23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERDOT23X    : num  0 0 0 0 0 0 0 0 0 0 ...\n $ ERDXP23X    : num  192.5 386.8 288.5 8.6 0 ...\n $ ERDTC23X    : num  1822 1361 1357 35.2 245 ...\n $ IMPFLAG     : int  2 3 2 3 3 2 0 0 1 2 ...\n $ PERWT23F    : num  12163 9677 29407 29407 39688 ...\n $ VARSTR      : int  2064 2104 2045 2045 2045 2008 2055 2055 2025 2025 ...\n $ VARPSU      : int  3 3 3 3 3 2 3 3 3 3 ...\n\nOGData_clean &lt;- OGData %&gt;% #only took variables greater than 0\n  filter(\n    # ── RQ1 & RQ2: Tests, diagnostics, and services received ──\n    MRI_M18     &gt;= 0,    # MRI/CT scan\n    SURGPROC    &gt;= 0,    # Surgery performed\n    XRAYS_M18   &gt;= 0,    # X-rays\n    LABTEST_M18 &gt;= 0,    # Lab tests\n    EKG_M18     &gt;= 0,    # EKG/ECG\n    SONOGRAM_M18 &gt;= 0,   # Ultrasound\n    MAMMOG_M18  &gt;= 0,    # Mammogram\n    RCVVAC_M18  &gt;= 0,    # Vaccination\n    MEDPRESC    &gt;= 0,    # Medicine prescribed\n    VSTRELCN    &gt;= 0,    # Related to specific condition?\n    \n    # ── RQ2: Total expenditure and weight ──\n    ERXP23X     &gt;= 0,    # Total ER expenditure (main outcome)\n    PERWT23F    &gt;  0,    # Survey weight (always positive)\n    \n    # ── RQ1: Admission flag ──\n    ERHEVIDX    &gt;= -1,   # -1 = treat-and-release, &gt;0 = admitted (allow -1!)\n    \n    # ── RQ3: Out-of-pocket and payment sources (facility + doctor) ──\n    ERFSF23X    &gt;= 0,    # OOP facility - this is Out of pocket costs to the facility / ER visit room\n    ERDSF23X    &gt;= 0,    # OOP doctor - out of pocket costs to the doctors\n    ERFPV23X    &gt;= 0,    # Private insurance payment (facility)\n    ERDPV23X    &gt;= 0,    # Private insurance payment (doctor)\n    ERFMD23X    &gt;= 0,    # Medicaid payment (facility)\n    ERDMD23X    &gt;= 0,    # Medicaid payment (doctor)\n    ERFMR23X    &gt;= 0,    # Medicare payment (facility)\n    ERDMR23X    &gt;= 0     # Medicare payment (doctor)\n  )\n\ndim(OGData) #4241\n\n[1] 4241   53\n\ndim(OGData_clean) #3924\n\n[1] 3924   53\n\n\nRenaming Variables\n\nOGData_clean &lt;- OGData %&gt;%\n  # ── Keep only the variables we actually use across all 3 RQs ──\ndplyr:: select(\n    # Person-level ID and survey weight\n    person_id   = DUPERSID,\n    weight      = PERWT23F,\n    \n    # ── RQ1: Predict hospital admission ──\n    admitted    = ERHEVIDX,        # will recode below\n    \n    # Tests & diagnostics performed in ER (all yes/no → 0/1)\n    mri_ct      = MRI_M18,\n    surgery     = SURGPROC,\n    xray        = XRAYS_M18,\n    lab_tests   = LABTEST_M18,\n    ekg         = EKG_M18,\n    ultrasound  = SONOGRAM_M18,\n    mammogram   = MAMMOG_M18,\n    vaccination = RCVVAC_M18,\n    rx_given    = MEDPRESC,\n    related_condition = VSTRELCN,\n    \n    # ── RQ2: Total ER cost drivers ──\n    total_cost  = ERXP23X,         # total expenditure (facility + doctor)\n    \n    # ── RQ3: Out-of-pocket by insurance ──\n    oop_facility = ERFSF23X,       # self/family OOP facility\n    oop_doctor   = ERDSF23X,       # self/family OOP doctor\n    \n    private_fac  = ERFPV23X,\n    private_doc  = ERDPV23X,\n    medicaid_fac = ERFMD23X,\n    medicaid_doc = ERDMD23X,\n    medicare_fac = ERFMR23X,\n    medicare_doc = ERDMR23X\n  )\n\nAdding in Insurance Information\n\n#Cleaning Data to find Insurance v No Insurance\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(Insurance = case_when(\n    (private_fac &gt; 0  |  private_doc &gt; 0 | medicaid_fac &gt; 0 | medicaid_doc &gt; 0 | medicare_fac &gt; 0 | medicare_doc &gt; 0) ~ \"1\",\n    TRUE ~ \"0\"\n  ))\n\nOGData_clean$Insurance &lt;- as.numeric(OGData_clean$Insurance)\n\nCleaning up binary data Clean More Data - Deal with 95 & 1&2 to 0,1 remove -8 dont know variables 1 is yes 2 is no - changing to 0,1 - no - 0 yes 1\n\nyesno_vars &lt;- c(\n  \"mri_ct\", \"surgery\", \"xray\", \"lab_tests\", \"ekg\",\n  \"ultrasound\", \"mammogram\", \"vaccination\", \"rx_given\",\n  \"related_condition\")\n\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(across(all_of(yesno_vars), ~ ifelse(. == 1, 1, 0))) #keeps all the 1's and replaces the rest with 0\n\n#cleaning admitted inpatient for RQ1\nOGData_clean$admitted &lt;- ifelse(OGData_clean$admitted == \"-1\", 0, 1) #-1 not admitted - changing to 0;; recoding 1 to be admitted\ntable(OGData_clean$admitted) #not admitted 3345; admitted:896\n\n\n   0    1 \n3345  896 \n\n\nRQ2 Question 2. Which characteristics of an ER visit (specific tests, procedures, or diagnoses) are most strongly associated with the highest total ER expenditures? A lot of outliers\nMaking Dataset for RQ2\n\nRQ2Data &lt;- OGData_clean %&gt;%\n  dplyr:: select( admitted,       \n    mri_ct      ,\n    surgery,\n    xray ,\n    lab_tests ,\n    ekg    ,\n    ultrasound ,\n    mammogram ,\n    vaccination ,\n    rx_given ,\n    related_condition,\n    total_cost)\n\nExploring Dataset / Characteristics\n\nsummary (RQ2Data$total_cost) #Median - 578, Mean 1227.9 Max: 195314.5\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n     0.0    206.7    578.2   1227.9   1272.0 195314.5 \n\nsum(RQ2Data$total_cost == 0, na.rm = TRUE) #367 cases with 0 out of pocket cost\n\n[1] 367\n\nsum(RQ2Data$total_cost != 0, na.rm = TRUE) #3874 cases with more than 0 out of pocket\n\n[1] 3874\n\nRQ2DataViz &lt;- RQ2Data %&gt;%\nmutate(cost_group = ifelse(total_cost == 0, \"0\", \"&gt;0\"))\n\n#Bar Chart showing majority has more than $0 Costs\nggplotly (ggplot(RQ2DataViz, aes(x = cost_group, fill = cost_group)) +\ngeom_bar() +\nxlab(\"Total Cost\") +\nylab(\"Count\") +\nggtitle(\"Count of 0 vs &gt;0 Total Cost\") +\ntheme_minimal())\n\n\n\n\n#Boxplot of Total Cost\nggplotly(ggplot(RQ2Data, aes(x = \"\", y = total_cost)) +\ngeom_boxplot(fill = \"steelblue\")\n  + # focus on main range\n  ggtitle(\"Total Cost Distribution of ER Visits\") +\n  xlab(\"Total Cost ($)\") +\n  ylab(\"Count\")+\ncoord_cartesian(ylim = c(0, 5000))) #this was able to show the box because of so many outliers / noise\n\n\n\n\n#showing the distribution of total cost\nggplot(RQ2Data, aes(x = total_cost)) +\n  geom_histogram(bins = 50, fill = \"steelblue\", alpha = 0.7) +\n  scale_x_continuous(limits = c(0, 5000)) + # focus on main range\n  ggtitle(\"Total Cost Distribution of ER Visits\") +\n  xlab(\"Total Cost ($)\") +\n  ylab(\"Count\") +\n  theme_minimal() \n\nWarning: Removed 143 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\n\n\n\n\nRandom Forest Model because a lot of outliers\n\nlibrary(randomForest)\nlibrary(caret)\n\nset.seed(1)\ntrain_index1 = createDataPartition(RQ2Data$total_cost, p = 0.7, list = FALSE) \ntrain_data1 = RQ2Data[train_index1, ]\ntest_data1 = RQ2Data[-train_index1, ]\n\n\nrf.RQ2=randomForest(total_cost~.,data=train_data1, ntree = 500, importance = TRUE)\nvarImpPlot(rf.RQ2)\n\n\n\n\n\n\n\nrf.RQ2\n\n\nCall:\n randomForest(formula = total_cost ~ ., data = train_data1, ntree = 500,      importance = TRUE) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n          Mean of squared residuals: 18580813\n                    % Var explained: -0.61\n\nplot(rf.RQ2)\n\n\n\n\n\n\n\nimportance(rf.RQ2)\n\n                    %IncMSE IncNodePurity\nadmitted          14.376686    1585193233\nmri_ct            -4.318056    1206731706\nsurgery            4.246764     687400807\nxray              -4.163164     650707731\nlab_tests         -2.063632     336158929\nekg               -7.535712     718870055\nultrasound        -5.872499    1312888800\nmammogram          1.906166       5543703\nvaccination        1.859166      34182634\nrx_given          -3.315633     497315760\nrelated_condition -3.269431     120239145\n\nsummary (rf.RQ2)\n\n                Length Class  Mode     \ncall               5   -none- call     \ntype               1   -none- character\npredicted       2970   -none- numeric  \nmse              500   -none- numeric  \nrsq              500   -none- numeric  \noob.times       2970   -none- numeric  \nimportance        22   -none- numeric  \nimportanceSD      11   -none- numeric  \nlocalImportance    0   -none- NULL     \nproximity          0   -none- NULL     \nntree              1   -none- numeric  \nmtry               1   -none- numeric  \nforest            11   -none- list     \ncoefs              0   -none- NULL     \ny               2970   -none- numeric  \ntest               0   -none- NULL     \ninbag              0   -none- NULL     \nterms              3   terms  call     \n\n#REGRESSION ANALYSIS FOR CONTINUOUS VARIABLE\n# Make predictions on the test set\npredictionsRQ2 = predict(rf.RQ2, newdata = test_data1)\n\n# Evaluate the model performance\n# Regression metrics\nrmse &lt;- sqrt(mean((test_data1$total_cost - predictionsRQ2)^2)) #RMSE 997.89\nmae  &lt;- mean(abs(test_data1$total_cost - predictionsRQ2)) #MAE: 243.08\nrsq  &lt;- cor(test_data1$total_cost, predictionsRQ2)^2 #RSQLM: 0.97\n\nMultiple Linear Regression Model\n\nfit = lm(total_cost ~ ., data = train_data1)\npred_lm = predict(fit, newdata = test_data1)\n\nsummary(fit)\n\n\nCall:\nlm(formula = total_cost ~ ., data = train_data1)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -3574   -897   -432    295 191939 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         867.75     227.04   3.822 0.000135 ***\nadmitted          -1589.18     201.76  -7.877 4.68e-15 ***\nmri_ct              936.09     188.78   4.958 7.51e-07 ***\nsurgery             495.41     341.66   1.450 0.147165    \nxray                112.29     166.11   0.676 0.499099    \nlab_tests           336.39     169.31   1.987 0.047028 *  \nekg                 384.07     208.61   1.841 0.065704 .  \nultrasound          648.08     251.73   2.574 0.010088 *  \nmammogram          -437.42    1901.22  -0.230 0.818052    \nvaccination        -511.64     639.53  -0.800 0.423760    \nrx_given            -64.81     175.65  -0.369 0.712158    \nrelated_condition    90.41     227.79   0.397 0.691458    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4236 on 2958 degrees of freedom\nMultiple R-squared:  0.03225,   Adjusted R-squared:  0.02865 \nF-statistic: 8.962 on 11 and 2958 DF,  p-value: 6.634e-16\n\nsqrt(mean((test_data1$total_cost - pred_lm)^2)) #RMSE 3689.77\n\n[1] 3904.452\n\nmean(abs(test_data1$total_cost - pred_lm)) #MAE: 1147.58\n\n[1] 1241.836\n\ncor(test_data1$total_cost, pred_lm)^2 #RSQLM:0.1324599\n\n[1] 0.0279998"
  },
  {
    "objectID": "RQ3-.html",
    "href": "RQ3-.html",
    "title": "RQ3",
    "section": "",
    "text": "RQ 3: 3. Do uninsured patients recieve less tests compared to insured?\n\nOGData= read.csv(\"C:/Users/diane/downloads/h248e.csv\")\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.5.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.4.1 ──\n\n\n✔ broom        1.0.10     ✔ recipes      1.3.1 \n✔ dials        1.4.2      ✔ rsample      1.3.1 \n✔ dplyr        1.1.4      ✔ tailor       0.1.0 \n✔ ggplot2      4.0.1      ✔ tidyr        1.3.1 \n✔ infer        1.0.9      ✔ tune         2.0.1 \n✔ modeldata    1.5.1      ✔ workflows    1.3.0 \n✔ parsnip      1.3.3      ✔ workflowsets 1.1.1 \n✔ purrr        1.1.0      ✔ yardstick    1.3.2 \n\n\nWarning: package 'dials' was built under R version 4.5.2\n\n\nWarning: package 'dplyr' was built under R version 4.5.2\n\n\nWarning: package 'ggplot2' was built under R version 4.5.2\n\n\nWarning: package 'infer' was built under R version 4.5.2\n\n\nWarning: package 'modeldata' was built under R version 4.5.2\n\n\nWarning: package 'parsnip' was built under R version 4.5.2\n\n\nWarning: package 'recipes' was built under R version 4.5.2\n\n\nWarning: package 'rsample' was built under R version 4.5.2\n\n\nWarning: package 'tailor' was built under R version 4.5.2\n\n\nWarning: package 'tune' was built under R version 4.5.2\n\n\nWarning: package 'workflows' was built under R version 4.5.2\n\n\nWarning: package 'workflowsets' was built under R version 4.5.2\n\n\nWarning: package 'yardstick' was built under R version 4.5.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.5.2\n\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-10\n\nlibrary(xgboost)\n\nWarning: package 'xgboost' was built under R version 4.5.2\n\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.5.2\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.5.2\n\nlibrary(randomForest)\n\nWarning: package 'randomForest' was built under R version 4.5.2\n\n\nrandomForest 4.7-1.2\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:ranger':\n\n    importance\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nlibrary(tree)\n\nWarning: package 'tree' was built under R version 4.5.2\n\nlibrary(ISLR)\n\nWarning: package 'ISLR' was built under R version 4.5.2\n\nlibrary(dplyr)\nlibrary (plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:xgboost':\n\n    slice\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nRenaming Variables\n\nlibrary (dplyr)\nlibrary(dplyr)\n\nOGData_clean &lt;- OGData %&gt;%\n  # ── Keep only the variables we actually use across all 3 RQs ──\ndplyr:: select(\n    # Person-level ID and survey weight\n    person_id   = DUPERSID,\n    weight      = PERWT23F,\n    \n    # ── RQ1: Predict hospital admission ──\n    admitted    = ERHEVIDX,        # will recode below\n    \n    # Tests & diagnostics performed in ER (all yes/no → 0/1)\n    mri_ct      = MRI_M18,\n    surgery     = SURGPROC,\n    xray        = XRAYS_M18,\n    lab_tests   = LABTEST_M18,\n    ekg         = EKG_M18,\n    ultrasound  = SONOGRAM_M18,\n    mammogram   = MAMMOG_M18,\n    vaccination = RCVVAC_M18,\n    rx_given    = MEDPRESC,\n    related_condition = VSTRELCN,\n    \n    # ── RQ2: Total ER cost drivers ──\n    total_cost  = ERXP23X,         # total expenditure (facility + doctor)\n    \n    # ── RQ3: Out-of-pocket by insurance ──\n    oop_facility = ERFSF23X,       # self/family OOP facility\n    oop_doctor   = ERDSF23X,       # self/family OOP doctor\n    \n    private_fac  = ERFPV23X,\n    private_doc  = ERDPV23X,\n    medicaid_fac = ERFMD23X,\n    medicaid_doc = ERDMD23X,\n    medicare_fac = ERFMR23X,\n    medicare_doc = ERDMR23X\n  )\n\nCleaning up binary data Clean More Data - Deal with 95 & 1&2 to 0,1 remove -8 dont know variables 1 is yes 2 is no - changing to 0,1 - no - 0 yes 1\n\nyesno_vars &lt;- c(\n  \"mri_ct\", \"surgery\", \"xray\", \"lab_tests\", \"ekg\",\n  \"ultrasound\", \"mammogram\", \"vaccination\", \"rx_given\",\n  \"related_condition\")\n\nOGData_clean &lt;- OGData_clean %&gt;%\n  mutate(across(all_of(yesno_vars), ~ ifelse(. == 1, 1, 0))) #keeps all the 1's and replaces the rest with 0\n\n#cleaning admitted inpatient for RQ1\nOGData_clean$admitted &lt;- ifelse(OGData_clean$admitted == \"-1\", 0, 1) #-1 not admitted - changing to 0;; recoding 1 to be admitted\n\nAdding in Insurance Information\n\n#Cleaning Data to find Insurance v No Insurance\nRQ3Data &lt;- OGData_clean %&gt;%\n  mutate(Insurance = case_when(\n    (private_fac &gt; 0  |  private_doc &gt; 0 | medicaid_fac &gt; 0 | medicaid_doc &gt; 0 | medicare_fac &gt; 0 | medicare_doc &gt; 0) ~ \"1\",\n    TRUE ~ \"0\"\n  ))\n\nRQ3Data$Insurance &lt;- as.numeric(RQ3Data$Insurance)\n\n#Count the total number of tests / procedures done for pt\ntest_vars &lt;- c(\"mri_ct\", \"surgery\", \"xray\", \"lab_tests\", \n               \"ekg\", \"ultrasound\", \"mammogram\", \n               \"vaccination\", \"rx_given\", \"related_condition\")\n\n# Create new variable\nRQ3Data &lt;- RQ3Data %&gt;%\n  rowwise() %&gt;%\n  mutate(total_tests = sum(c_across(all_of(test_vars)), na.rm = TRUE)) %&gt;%\n  ungroup()\n\nRQ3Data&lt;- RQ3Data %&gt;%\n  dplyr:: select(Insurance, total_tests,person_id) #added ID or dupersid to merge later\n\nMerging New Dataset\n\nlibrary(haven)\nlibrary(dplyr)\n\n#dowloaded the SAS File & filtering only the variables needed\nMergeDataDemo &lt;- read_sas(\"C:/Users/diane/Downloads/h251.sas7bdat\") %&gt;%\n  dplyr::select(DUPERSID, SEX,#1 male, 2 female\n                POVCAT23) #1 is low income to 5 high\n\nRQ3Data &lt;- RQ3Data %&gt;%\n  mutate(person_id = as.numeric(person_id))\n\nMergeDataDemo &lt;- MergeDataDemo %&gt;%\n  mutate(DUPERSID = as.numeric(DUPERSID))\n\nMergedDataRQ3 &lt;- RQ3Data %&gt;%\n  left_join(MergeDataDemo, by = c(\"person_id\" = \"DUPERSID\"))\n\nMergedDataRQ3 &lt;- MergedDataRQ3 %&gt;%\n   dplyr::select(-person_id)#no need after merge\n\n#changing sex to 0,1 (male 0 female 1)\nMergedDataRQ3 &lt;- MergedDataRQ3 %&gt;%\n  mutate(SEX = ifelse(SEX == 1, 0,\n                      ifelse(SEX == 2, 1, NA)))\n\n#Missing Data\nsum(is.na(MergedDataRQ3)) #no missing\n\n[1] 0\n\n\nData Visualization\n\nlibrary (ggplot2)\nlibrary (plotly)\n#making the visualization show yes / no\nRQ3Viz &lt;- MergedDataRQ3 %&gt;%\n  mutate(Insurance = factor(Insurance,\n                            levels = c(0, 1),\n                            labels = c(\"No\", \"Yes\")))\n\n\nggplotly(ggplot(RQ3Viz, aes(x = factor(POVCAT23), fill = Insurance)) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"Poverty Category\", y = \"Count\",\n       title = \"Poverty Category by Insurance Status\"))\n\n\n\n\n#high income has a higher no insurance rate than the very low\n\n#table of insurance & poverty category\ntable(RQ3Viz$Insurance, RQ3Viz$POVCAT23)\n\n     \n        1   2   3   4   5\n  No  144  34  77 211 178\n  Yes 833 276 581 913 994\n\nprop.table(table(RQ3Viz$Insurance, RQ3Viz$POVCAT23), margin = 1) * 100 #proporations\n\n     \n              1         2         3         4         5\n  No  22.360248  5.279503 11.956522 32.763975 27.639752\n  Yes 23.158187  7.673061 16.152349 25.382263 27.634140\n\ntable (RQ3Viz$Insurance)# Imbalanced data 644 No insurance 3597 Insurance\n\n\n  No  Yes \n 644 3597 \n\ntable (RQ3Viz$total_tests)\n\n\n   0    1    2    3    4    5    6    7    8 \n 145  735 1230 1050  653  306   98   19    5 \n\nstr (RQ3Viz) #all numerical\n\ntibble [4,241 × 4] (S3: tbl_df/tbl/data.frame)\n $ Insurance  : Factor w/ 2 levels \"No\",\"Yes\": 2 2 2 2 1 2 2 2 2 2 ...\n $ total_tests: num [1:4241] 3 3 2 5 3 3 3 2 3 3 ...\n $ SEX        : num [1:4241] 0 1 0 0 0 1 1 1 1 0 ...\n $ POVCAT23   : num [1:4241] 1 5 3 3 5 3 5 5 4 4 ...\n  ..- attr(*, \"label\")= chr \"FAMILY INC AS % OF POVERTY LINE - CATEGORICAL\"\n\nprop.table(table(RQ3Viz$Insurance, RQ3Viz$total_tests), margin = 1) * 100\n\n     \n                0           1           2           3           4           5\n  No   2.95031056 16.92546584 27.95031056 21.27329193 16.77018634  8.69565217\n  Yes  3.50291910 17.40339172 29.19099249 25.38226300 15.15151515  6.95023631\n     \n                6           7           8\n  No   3.88198758  1.24223602  0.31055901\n  Yes  2.02946900  0.30581040  0.08340284\n\n#left skewed normal distribution - try to add a line showing the distribution - create different one then overlap?\nggplotly(ggplot(RQ3Viz, aes(x = factor(total_tests), fill = factor(Insurance))) +\n  geom_bar(position = \"dodge\") +\n  labs(\n    title = \"Number of ER Tests by Insurance Status\",\n    x = \"Total Tests/Procedures\",\n    y = \"Number of Patients\",\n    fill = \"Insurance\"\n  ) +\n  theme_minimal())\n\n\n\n\n\nMultiple Linear Regression\n\nlibrary (caret)\n\nWarning: package 'caret' was built under R version 4.5.2\n\n\nLoading required package: lattice\n\n\n\nAttaching package: 'caret'\n\n\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n\n\nThe following object is masked from 'package:rsample':\n\n    calibration\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nset.seed(1)\ntrain_index3 &lt;- createDataPartition(MergedDataRQ3$total_tests, \n                                    p = 0.7, \n                                    list = FALSE)\n\n# Training and testing datasets\ntrain_data3 &lt;- MergedDataRQ3[train_index3, ]\ntest_data3 &lt;- MergedDataRQ3[-train_index3, ]\n\n#traing on train data\nfit3 &lt;- lm(total_tests ~ factor(Insurance) + factor(SEX) + factor(POVCAT23),\n           data = train_data3)\n#Test on test\npred_lm3 = predict(fit3, newdata = test_data3)\n\nsummary(fit3)\n\n\nCall:\nlm(formula = total_tests ~ factor(Insurance) + factor(SEX) + \n    factor(POVCAT23), data = train_data3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9708 -0.8006  0.0292  1.0552  5.2626 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         2.73161    0.08486  32.188  &lt; 2e-16 ***\nfactor(Insurance)1 -0.17027    0.07134  -2.387 0.017067 *  \nfactor(SEX)1       -0.02602    0.05236  -0.497 0.619282    \nfactor(POVCAT23)2   0.11644    0.11075   1.051 0.293184    \nfactor(POVCAT23)3   0.02835    0.08245   0.344 0.731004    \nfactor(POVCAT23)4   0.00577    0.07258   0.079 0.936645    \nfactor(POVCAT23)5   0.23923    0.07195   3.325 0.000896 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.386 on 2963 degrees of freedom\nMultiple R-squared:  0.007598,  Adjusted R-squared:  0.005588 \nF-statistic: 3.781 on 6 and 2963 DF,  p-value: 0.0009368\n\n#Performance on Test Data\nRMSE(pred_lm3, test_data3$total_tests) #1.37 RMSE\n\n[1] 1.373271\n\nmean(abs(test_data3$total_tests - pred_lm3)) #1.115986 MAE\n\n[1] 1.115986\n\ncor(test_data3$total_tests, pred_lm3)^2 #0.007887108 RSQLM\n\n[1] 0.007887108\n\nvar(test_data3$total_tests) #1.9 most people in the data has 1.9 tests done - mean with fewer high/lower; low variance\n\n[1] 1.902351\n\n#hm = lm(Insurance ~ SEX, data = MergedDataRQ3)\n#summary (hm) #Being female (SEX = 1) increases probability of being insured by ~6.6%, holding everything else constant.\n\nPoisson regression\n\nset.seed(1)\n\n#Poisson Model on Train Data\nmodel_pois &lt;- glm(total_tests ~ factor(Insurance) + factor(SEX) + factor(POVCAT23),\n                  family = poisson(link = \"log\"), data = train_data3)\n#making prediction on test data\nPoss_pred_lm3 = predict(model_pois, newdata = test_data3,type = \"response\")\n\nsummary(model_pois)\n\n\nCall:\nglm(formula = total_tests ~ factor(Insurance) + factor(SEX) + \n    factor(POVCAT23), family = poisson(link = \"log\"), data = train_data3)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)         1.003330   0.037225  26.953  &lt; 2e-16 ***\nfactor(Insurance)1 -0.062767   0.030934  -2.029  0.04245 *  \nfactor(SEX)1       -0.009803   0.023172  -0.423  0.67225    \nfactor(POVCAT23)2   0.044392   0.049095   0.904  0.36588    \nfactor(POVCAT23)3   0.010936   0.037021   0.295  0.76768    \nfactor(POVCAT23)4   0.002358   0.032623   0.072  0.94237    \nfactor(POVCAT23)5   0.088898   0.031737   2.801  0.00509 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2338.2  on 2969  degrees of freedom\nResidual deviance: 2322.0  on 2963  degrees of freedom\nAIC: 10379\n\nNumber of Fisher Scoring iterations: 4\n\nRMSE(test_data3$total_tests, Poss_pred_lm3) #1.373308 RMSE\n\n[1] 1.373308\n\nmean(abs(test_data3$total_tests - Poss_pred_lm3)) #1.116015 MAE\n\n[1] 1.116015\n\ncor(test_data3$total_tests, Poss_pred_lm3)^2 #0.007838005 RSQLM\n\n[1] 0.007833137\n\n\nRandom Forest Regression\n\nlibrary(randomForest)\n\ntrain_data3 &lt;- MergedDataRQ3[train_index3, ]\ntest_data3 &lt;- MergedDataRQ3[-train_index3, ]\n\nrf.RQ3=randomForest(total_tests~.,data=train_data3, ntree = 500, importance = TRUE)\n\n#REGRESSION ANALYSIS FOR CONTINUOUS VARIABLE\n# Make predictions on the test set\npredictionsRQ3 = predict(rf.RQ3, newdata = test_data3)\n\nvarImpPlot(rf.RQ3)\n\n\n\n\n\n\n\nrf.RQ3\n\n\nCall:\n randomForest(formula = total_tests ~ ., data = train_data3, ntree = 500,      importance = TRUE) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 1\n\n          Mean of squared residuals: 1.922564\n                    % Var explained: 0.42\n\nplot(rf.RQ3)\n\n\n\n\n\n\n\nimportance(rf.RQ3)\n\n            %IncMSE IncNodePurity\nInsurance  8.256505     12.065347\nSEX        4.307670      7.157186\nPOVCAT23  18.839742     31.904179\n\nsummary (rf.RQ3)\n\n                Length Class  Mode     \ncall               5   -none- call     \ntype               1   -none- character\npredicted       2970   -none- numeric  \nmse              500   -none- numeric  \nrsq              500   -none- numeric  \noob.times       2970   -none- numeric  \nimportance         6   -none- numeric  \nimportanceSD       3   -none- numeric  \nlocalImportance    0   -none- NULL     \nproximity          0   -none- NULL     \nntree              1   -none- numeric  \nmtry               1   -none- numeric  \nforest            11   -none- list     \ncoefs              0   -none- NULL     \ny               2970   -none- numeric  \ntest               0   -none- NULL     \ninbag              0   -none- NULL     \nterms              3   terms  call     \n\n# Evaluate the model performance on test\n# Regression metrics\nsqrt(mean((test_data3$total_tests - predictionsRQ3)^2)) #RMSE 1.371164\n\n[1] 1.372646\n\nmean(abs(test_data3$total_tests - predictionsRQ3)) #MAE: 1.116\n\n[1] 1.117072\n\ncor(test_data3$total_tests , predictionsRQ3)^2 #RSQLM: 0.01054665\n\n[1] 0.0104738\n\n\nProblem of Insurance with Multiple Insurance Types\nDo uninsured patients pay more out of pocket?\nAccess to Services/Procedures: Are uninsured individuals less likely to receive advanced diagnostic procedures (e.g., MRI_M18, XRAYS_M18, LABTEST_M18) or surgeries (SURGPROC) during ER visits compared to insured individuals in 2023? Rationale: Insurance may enable more comprehensive care; stratify by visit category (VSTCTGRY) or condition-relatedness (VSTRELCN)."
  }
]